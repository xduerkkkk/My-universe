主要从三个维度对记忆进行分类与梳理：

- 对象维度：个人记忆与系统记忆；
    
- 形式维度：非参数记忆与参数记忆；
    
- 时间维度：短期记忆与长期记忆。


##### 对象维度

该维度与大语言模型 AI 系统和人类的交互密切相关，根据信息的来源与用途对其进行分类：

- 一方面，系统接收人类的输入与反馈，形成 “个人记忆”；
    
- 另一方面，系统执行任务时会产生一系列中间输出结果，形成 “系统记忆”。
    

个人记忆帮助系统加深对用户行为的理解、增强个性化能力；系统记忆则可提升系统的推理能力，例如 “思维链”（CoT）[23]、“推理 - 动作协同”（ReAct）[24] 等方法均依赖系统记忆。



##### 形式维度

该维度聚焦大语言模型 AI 系统中记忆的表示与存储方式，决定信息的编码与提取逻辑：

- 部分记忆通过训练嵌入模型参数，形成 “参数记忆”；
    
- 另一部分记忆以结构化数据库或检索机制的形式存储于模型外部，形成 “非参数记忆”。
    

非参数记忆可作为补充知识源，供大语言模型动态访问，提升实时检索相关信息的能力，例如 “检索增强生成”（RAG）[25] 技术即基于非参数记忆实现。

##### 时间维度

该维度定义记忆的保留时长，以及不同时间尺度下记忆对大语言模型交互的影响：

- 短期记忆：指在当前对话中临时保留的上下文信息，确保多轮对话的连贯性与连续性；
    
- 长期记忆：指存储在外部数据库中的过往交互信息，需用时调取，使模型能保留用户专属知识，长期提升个性化水平。


## 个人记忆
### 3.1 上下文相关个人记忆

在个人记忆中，可加载的非参数化上下文记忆通常分为两类：当前会话多轮对话的短期记忆，以及跨会话历史对话的长期记忆。前者能有效补充上下文信息，后者可填补信息空缺并突破上下文长度限制。

#### 3.1.1 加载多轮对话（第一象限）

在多轮对话场景中，当前会话的对话历史能显著提升大语言模型驱动的人工智能系统对用户实时意图的理解，进而生成更具相关性与上下文适配性的响应。如今，许多对话系统已具备处理多轮对话的能力，并在响应时充分考虑当前对话上下文。典型案例包括 ChatGPT [26]、DeepSeek-Chat [27]、Claude [28] 等，这些系统在长时间交互中仍能维持响应的连贯性与相关性。
以 ChatGPT [26] 为例，它是典型的多轮对话系统 —— 当前会话的对话历史会作为短期记忆，用于补充对话上下文信息。在 ChatGPT 中，对话记忆以 “角色 - 内容” 格式编码，明确区分 “用户”“助手” 等角色，确保系统清晰追踪说话者身份与对话流程。通过 “助手（Assistant）、会话线程（Threads）、消息（Messages）、执行步骤（Runs）” 等不同层级的对话管理，系统能精准追踪对话每一轮、每一步的状态，保障交互的连续性与一致性。此外，当对话长度过长时，系统会通过截断对话轮次来管理输入，避免输入超出模型的长度限制，从而在不丢失关键上下文的前提下持续处理对话，维持多轮交互的有效性。
#### 3.1.2 记忆检索增强生成（第二象限）

在跨会话对话场景中，从历史对话中调取用户相关的长期记忆，可有效补充当前会话中缺失的信息（如个人偏好、人物关系等）。记忆检索增强生成的优势在于：大语言模型无需加载所有跨会话对话 —— 即便模型上下文窗口已扩展至数百万token，从历史会话中调取相关信息仍能大幅提升计算效率、降低成本。除跨会话对话外，长期个人记忆还涵盖用户长期行为历史、偏好及与人工智能代理的交互记录等内容。

通过利用长期记忆中的检索增强生成技术，大语言模型驱动的人工智能系统能更好地定制响应和行为，进而提升用户满意度与参与度。例如，记住用户偏好新闻来源的个人助手，可在每日简报中优先推送这些来源的内容；而了解用户过往观看习惯的推荐系统，能推荐更符合用户喜好的内容。目前，许多商业和开源平台都在努力为个性化人工智能系统构建和利用长期记忆 —— 例如，面向个人助手的 ChatGPT Memory [18] 和 Me.bot [36]，以及作为开源框架的 MemoryScope [21] 和 mem0 [20]。长期个人记忆通常遵循四个核心处理阶段：构建、管理、检索和使用。


### 记忆构建

用户记忆的构建需要从多轮对话等原始记忆数据中提取并提炼信息。这一过程类似于人类的记忆巩固 —— 即稳定并强化记忆以实现长期存储的过程。结构清晰的长期记忆既能提升用户记忆的存储效率，也能增强其检索有效性。例如，MemoryBank [17] 利用记忆模块存储对话历史和关键事件摘要，从而构建长期用户画像；类似地，RET-LLM [44] 通过记忆模块保留外部世界的核心事实知识，使智能代理能监控并更新与用户相关的实时环境上下文。此外，为适配不同类型的记忆，研究人员开发了多种存储格式，包括键值对、图结构和向量表示：

  

- 键值对格式 [44,50,63]：便于高效访问用户事实、偏好等结构化信息；
    
- 图结构格式 [46,13,61,20]：用于捕捉和表示个体、事件等实体间的关系；
    
- 向量格式 [17,48,20]：通常由文本、视觉或音频记忆表示转换而来，用于编码对话的语义含义和上下文信息。
### 记忆管理

用户记忆的管理涉及对已构建记忆的进一步处理和优化，例如去重、合并和冲突解决。这一过程类似于人类的记忆再巩固与反思 —— 即重新激活、更新现有记忆并将其整合，以长期维持记忆的连贯性和相关性。例如：

  

- 反思性记忆管理（RMM）[52]：这是一种用户长期记忆管理框架，结合了用于动态摘要的 “前瞻性反思” 和通过强化学习优化检索的 “回顾性反思”，解决了记忆粒度僵化、检索机制固定等局限，提升了长期记忆管理的准确性和灵活性；
    
- LD-Agent [53]：通过动态角色建模模块为用户和代理构建个性化角色信息，并整合检索到的记忆优化响应生成，从而增强长期对话的个性化与一致性；
    
- A-MEM [54]：受 “卡片盒笔记法”（Zettelkasten method）[88] 启发，提出自组织记忆系统，通过动态索引、关联和记忆演化构建互联知识网络，使大语言模型代理能更灵活地组织、更新和检索长期记忆，进而提升任务适应性和上下文感知能力；
    
- MemoryBank [17]：融入受 “艾宾浩斯遗忘曲线”（Ebbinghaus Forgetting Curve）[89] 启发的记忆更新机制，使人工智能能根据时间推移和记忆的相对重要性，对记忆进行遗忘或强化，从而构建更贴近人类的记忆系统，提升用户体验。1

### 记忆检索

个人记忆的检索是指识别与用户当前请求相关的记忆条目，检索方法与记忆的存储方式密切相关：

  

- 针对键值对记忆：ChatDB [59] 通过结构化数据库上的 SQL 查询实现检索；而 RET-LLM [44] 采用模糊搜索检索三元组结构记忆 —— 这类记忆以 “两个实体通过预定义关系关联” 的形式存储信息；
    
- 针对图结构记忆：HippoRAG [13] 基于实体、短语和摘要构建知识图谱，以召回更相关、更全面的记忆；HippoRAG 2 [61] 则进一步将原始文本片段与基于短语的知识图谱结合，同时融入概念信息和上下文信息；
    
- 针对向量记忆：MemoryBank [17] 采用类似 “密集段落检索”（Dense Passage Retrieval）[90] 的双塔密集检索模型，精准识别相关记忆；生成的向量表示随后通过 FAISS [91] 建立索引，实现高效的基于相似度的检索。


用大白话拆解，主要讲了这 3 件事：

### 一、先搞懂 “人类记忆”，再对标 “AI 记忆”

人类记忆不是 “一个大仓库”，而是分了好多种类，各有各的用处，文档先把人类记忆拆清楚，再对应到 AI 的记忆逻辑上：

  

- **人类记忆怎么分？**  
    按 “保存时间” 分，有 “短期记忆” 和 “长期记忆”：
    

- 外显记忆：比如 “昨天吃了火锅”（ episodic 记忆，个人经历）、“地球绕太阳转”（ semantic 记忆，常识知识）；
    
- 内隐记忆：比如骑自行车、打字（ procedural 记忆，肌肉记忆），不用想步骤就能做。
    

- 短期记忆：比如记个临时电话号码、算数学题时记步骤（叫 “工作记忆”），只能存几秒到几分钟，用完可能就忘；还有 “感官记忆”，比如看到一闪而过的画面、听到一声响，瞬间就没了。
    
- 长期记忆：能存几分钟到一辈子，又分 “外显记忆”（能说出来的）和 “内隐记忆”（不用刻意想的）：
    

- **AI 记忆怎么对标人类？**  
    大语言模型的 AI 系统（比如 ChatGPT、智能助手），也有类似人类的记忆逻辑：
    

- 像 AI 对话时记当前几轮的聊天内容，对应人类的 “短期记忆”；
    
- 存用户长期偏好（比如 “用户不爱吃辣”）或系统自己的推理步骤（比如解数学题的思路），对应人类的 “长期记忆”；
    
- 甚至 AI 模型参数里内置的常识（比如 “猫是动物”），类似人类的 “语义记忆”；AI 练熟的特定技能（比如写代码的套路），类似 “内隐记忆”。
    

### 二、给 AI 记忆搞了个 “三维八象限” 分类，让混乱的研究变清晰

以前研究 AI 记忆，大多只看 “能存多久”（短期 / 长期），文档觉得不够，提出从 3 个维度给 AI 记忆分类，刚好分出 8 种类型（八象限），每种都有具体作用：

  

1. **维度 1：记 “什么内容”（对象）**
    

- 个人记忆：记和用户相关的，比如用户的喜好、聊天历史，用来让 AI 更个性化（比如知道你喜欢喝拿铁）；
    
- 系统记忆：记 AI 自己干活时产生的中间结果，比如推理步骤、搜索到的信息，用来帮 AI 更好地完成复杂任务（比如写报告时记收集到的资料）。
    

3. **维度 2：“怎么存”（形式）**
    

- 参数记忆：存在模型自己的参数里，比如训练时学会的知识（类似人类 “刻在脑子里” 的常识）；
    
- 非参数记忆：存在模型外面，比如数据库、文档里（类似人类记在笔记本上的内容，需要时去查）。
    

5. **维度 3：“能存多久”（时间）**
    

- 短期记忆：临时存，用完就丢（比如当前对话的上下文）；
    
- 长期记忆：长期存，下次还能用（比如用户一年前说过的偏好）。
    

  

这 8 种组合起来，每种都有实际例子：

比如 “个人 + 非参数 + 长期记忆”：ChatGPT Memory 存用户长期偏好；“系统 + 非参数 + 短期记忆”：AI 解数学题时记临时的推理步骤。

### 三、梳理当前 AI 记忆的研究，还指出未来要解决的问题

文档分别讲了 “个人记忆” 和 “系统记忆” 的现有研究，再提了未来的方向：

  

- **个人记忆：让 AI 更懂你**  
    比如怎么存用户的聊天历史（短期）、怎么快速查到用户几年前的偏好（长期），现在已有工具像 mem0、MemoryScope 能帮 AI 管理这些记忆，让 AI 回复更个性化。
    
- **系统记忆：让 AI 更会干活**  
    比如 AI 做复杂任务时，怎么记自己的推理思路（短期）、怎么总结过去的成功经验（比如 “上次这么做能解决问题”，长期），现在有方法让 AI 把有用的步骤存起来，下次遇到类似任务直接用。
    
- **未来要解决的问题**  
    现在的 AI 记忆还有很多不足，比如：
    

- 只能记文字，记不了图片、声音（要从 “单模态” 变 “多模态”）；
    
- 大多是固定存好的（静态），不能实时更新（要变 “流式记忆”，像人类实时记新信息）；
    
- 不同 AI 的记忆不互通（比如医疗 AI 和金融 AI 各记各的，未来要搞 “共享记忆”，互相帮衬）；
    
- 还要保护隐私（比如用户记忆不能泄露，甚至要保护一群人的集体隐私，不被滥用）



# 自己项目
其实感觉，跟这篇论文讲的，思路差不多了
系统记忆：让 AI 更会干活  未解决 
短期记忆，我很疑惑，就是每次调用api时的一次对话吗？调api模型只能记得这一次api的对话？
我们的记忆构建用了简单的字典，记忆管理也一样，记忆检索就是简单的匹配key，提取key 