# 项目整体
我感觉没有具体领域的灵感的话，可迁移功能很重要
先做出agent记忆架构（可迁移）
再去实现多智能体的一个功能

还有一个关于微调数据的
# agent的记忆
记忆的形式，json是不是更符合查询的规范一点？就像functioncall使用的json，不仅有内容还有属性？也就是把过去的聊天记录整理出关键点记忆？ 当然，我感觉也可以像简单的数据如txt或数据库，直接像我们之间对话一样，把所有以往的话都当作上下文一起输入，然后让llm输出，对于agent是不是因为特别频繁的使用，所以绝对不能这样？  
那他如何回忆呢？ 我觉得，如果是更符合查询的规范，就可以用rag技术，哦哦，就算不符合规范，纯文本数据也可以rag。 然后呢，还可以用llm，写提示词让llm找相关记忆点？  
知道了记忆，应该把需要提取的记忆当作上下文

我梳理一下，咱们目前是做agent记忆，然后记忆是用在哪，用在用户提问时，我们要选择记忆。  
这个选择就可以分流选，用户的问题有可能是固定的答案，简单的答案，我们调用我们准备好的整理的记忆，也有可能是复杂的问题，我们无法直接匹配，那我们就用向量数据库，rag一下。是这样的吧？  
然后现在我们思考的是，那个简单答案，我们到底怎么匹配？ 使用小模型，如bert-tiny，应该是训练出一些”问题-标签“对，微调大模型后，这下用户如果直接问小问题，那就直接提取标签，把记忆里那些对应标签的送入上下文就好了，对吧？
1. 用户提问。
    
2. “前台接待员” (bert-tiny分类器) **率先**处理，给问题贴上一个“标签”（比如structured_query）。
    
3. 系统根据这个“标签”，去执行相应的记忆提取策略（比如精确查找JSON）。
    
4. 将提取到的记忆和原始问题，一起打包成上下文，**最后**才交给“大脑”（LLM）去生成回答。


# 用户信息的解析

```json
{
  "user_profile": {
    "name": null,
    "gender": null,
    "birthday": null,
    "school": null,
    "occupation": null,
    "city": null
    
  },
  "preferences": {
    "topics_of_interest": [],
    "communication_style": null 
  }
}

```

er

也很多啊，profile里，age，major preference里 还有food 等等 咦，我在想，也许不需要预留位置？ 而是直接让llm与用户对话时，直接调用我们之前微调好的bert-tiny，去看用户每一句话（应该每句话分别做一次？） 是不是要符合fact_lookup 如果符合，那就直接让llm自己去想一个槽位，然后填到memory.json里 ！ 也就是，存入记忆，也用berttiny分类（只是看能不能分道fact_lookup) 记忆回忆，也是用bert-tiny去判断问题类型， 如果fact_lookup就去json查。感觉这样，有一种，耦合感？


# 项目架构

项目背景：想动手实现agent的记忆功能
思路：用户输入问题，我们了保持上下文连贯，和用户的体感，我们应该调用与用户的记录。即，模型的记忆。  在调用时，最粗暴就是之前的对话都塞过来作为对话窗口，这样很容易溢出的！    优雅一点呢？ 把对话都当成rag素材，进行rag。这样有啥缺点？ 感觉仍然不够精细化与资源最小化？ 
也许，我们可以经过一个仲裁模型。 将用户的话分为俩类，一类是 fact，这类话，有准确且唯一的信息回答，一类是**semantic**， 是语义类的， 是开放性的问题，我们需要跟语义相关的记忆素材来回答。这样分两类， fact直接从模型总结出的用户json中提取，
这样比所有类都扔进rag应该能节省资源？
那么现在关键要解决的就是
1. fact，如何形成用户json？ 如何提取用户json？
2. 仲裁，如何分类是fact还是semantic？
对于fact问题，
- 形成json，用seqtoseq，但我们先用gpt做可行性验证。形成后加入道我们的json
- 提取json，咦？怎么提取来着？ 这是不是只能用llm提取了？这里应该和形成json耦合
对于仲裁
- 使用bert，微调数据，训练好后就能好好分类了

现在，我们写最简单的部分，就是写为生成微调bert的数据这一过程写prompt？




## 项目设计
### 提示词
- 知识形成：

```
 你会接收一段输入，接收输入后，请你讲将用户的“事实陈述句”转换成JSON键值对。
 例如
- 输入："我住在阳光小区"
    
- 输出：{"address": "阳光小区"}
```


```
# ROLE
You are a highly intelligent knowledge extraction agent. Your sole purpose is to convert a user's factual statement into a structured, single-level JSON key-value pair.

# RULES
1.  The key should be in English, using snake_case (e.g., `favorite_movie`).
2.  The key should be as specific and self-explanatory as possible.
3.  The value must be the exact fact extracted from the text.
4.  If the input statement is not a clear fact (e.g., it's a question, a command, or an opinion), you MUST output an empty JSON object: `{}`.
5.  Your entire output must ONLY be the JSON object, with no extra text or explanations.

# EXAMPLES
- Input: "我住在阳光小区"
- Output: {"address": "阳光小区"}

- Input: "我最喜欢的颜色是蓝色。"
- Output: {"favorite_color": "蓝色"}

- Input: "我觉得今天天气不错"
- Output: {}

- Input: "我的生日是1990年10月5日"
- Output: {"birthday": "1990-10-05"}
```




- 仲裁知识

```
判断用户的话是属于fact_lookup还是semantic_search，fact_lookup是有唯一答案的，可查询的问题，semantic_search是无唯一答案的，发散的复杂语义问题
请你输出标签。如
- 输入："我住在哪个小区来着？"
    
- 输出："fact_lookup"
    
- 输入："我们上次聊了啥？"
    
- 输出："semantic_search"
```

```
# TASK
Your task is to classify the user's query into one of two categories: `fact_lookup` or `semantic_search`.

# DEFINITIONS
- `fact_lookup`: The query asks for a specific, singular piece of information that likely has a definitive answer stored as a key-value pair (e.g., "What is my name?").
- `semantic_search`: The query is open-ended, asks for a summary, an opinion, or information scattered across a conversation. It does not have a single, definitive answer in a knowledge base (e.g., "What are my interests?").

# RULES
- You must only output the category name, and nothing else.

# EXAMPLES
- Input: "我住在哪个小区来着？"
- Output: "fact_lookup"

- Input: "我们上次聊了啥？"
- Output: "semantic_search"

- Input: "提醒我一下我的邮箱地址。"
- Output: "fact_lookup"

- Input: "总结一下我对于模型可解释性的主要观点。"
- Output: "semantic_search"
```
