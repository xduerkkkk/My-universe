项目背景：想动手实现agent的记忆功能
思路：用户输入问题，我们了保持上下文连贯，和用户的体感，我们应该调用与用户的记录。即，模型的记忆。  在调用时，最粗暴就是之前的对话都塞过来作为对话窗口，这样很容易溢出的！    优雅一点呢？ 把对话都当成rag素材，进行rag。这样有啥缺点？ 感觉仍然不够精细化与资源最小化？ 
也许，我们可以经过一个仲裁模型。 将用户的话分为俩类，一类是 fact，这类话，有准确且唯一的信息回答，一类是**semantic**， 是语义类的， 是开放性的问题，我们需要跟语义相关的记忆素材来回答。这样分两类， fact直接从模型总结出的用户json中提取，
这样比所有类都扔进rag应该能节省资源？
那么现在关键要解决的就是
1. fact，如何形成用户json？ 如何提取用户json？
2. 仲裁，如何分类是fact还是semantic？
对于fact问题，
- 形成json，用seqtoseq，但我们先用gpt做可行性验证。形成后加入道我们的json
- 提取json，咦？怎么提取来着？ 这是不是只能用llm提取了？这里应该和形成json耦合
对于仲裁
- 使用bert，微调数据，训练好后就能好好分类了




我们想引入模型记忆 history
怎么用？
就是rag用
我认为fact不需要，咦，真的不需要吗？
当判断