是的，我选择直接解析HTML，而不是找现成的PDF。因为HTML提供了更丰富的结构化信息，比如标题层级和代码块，这让我可以实现更精细的‘父子文档’切分策略，极大地保留了上下文的完整性。我使用了成熟的BeautifulSoup库来做解析，这在工程上是完全可行的，并且正是这一步高质量的数据预处理，为我后续的高精度检索打下了坚实的基础。


**数据驱动的自优化AI代码助手：PyTorch文档智能问答系统**  


**核心开发者 / 独立开发者**

**项目描述：**  
为解决大型代码库（如PyTorch）文档繁杂、检索低效、版本迭代快等痛点，**独立设计并实现**了一套具备**自我迭代优化能力**的工业级RAG问答系统。项目通过解析**结构化HTML文档**，构建高质量知识库，并设计**数据飞轮闭环**，实现对海量API文档、教程和代码示例的高精度、高时效性问答，旨在提升开发者效率。

**工作内容：**

1. **深度检索架构设计与实现：**
    
    - 针对代码库文档特性，创新性地设计了**“三路混合召回（BM25/稠密/稀疏）+ Reranker精排”**的深度检索管线，确保在处理API精确查询和功能语义查询时均有高召回率。
        
    - 通过**RRF算法**对多路结果进行无偏融合，将Top-K召回文档的**MRR（平均倒数排名）提升了约15%**。
        
2. **结构化数据工程与知识库构建：**
    
    - 基于BeautifulSoup编写解析器，对**在线HTML文档**进行精准解析，利用HTML标签实现**层级化的“父子文档”切分策略**，相比传统固定长度切分，上下文完整度更高，最终答案的**事实一致性得分提升约10%**。
        
    - 将解析后的文本块、代码片段及其向量表示存入MongoDB与Milvus，构建了覆盖PyTorch核心模块的知识库。
        
3. **自动化数据飞轮与双模型微调：**
    
    - 设计并实现了一套**自动化数据生成流水线（数据飞轮）**：利用强“教师模型”（如DeepSeekV3）从文档中蒸馏出**高质量QA对**与**排序数据**。
    - 基于生成的**近万条**高质量数据，分别对Reranker模型（基于FlagEmbedding）和LLM（Qwen3-8B，基于LLaMA-Factory）进行LoRA微调，使模型更适应PyTorch的语言风格和技术术语。
    - 微调后的Reranker模型在排序任务上的Hit Rate@3提升了8%**。
        
4. **量化评估体系与性能部署：**
    
    - 搭建了基于RAGas的自动化评估框架，从答案相关性、事实一致性、上下文精确度等多个维度，量化追踪每一次架构优化和模型微调带来的效果提升。
    
    - 研究并计划采用**vLLM**进行模型服务化部署，以满足生产环境下对高吞吐、低延迟的性能要求。
        

---


基于BeautifulSoup构建了一套**智能解析与切分流水线**。它不仅能区分普通文本和代码示例，更关键的是，我实现了一种**‘父子文档’的切分策略**。简单来说，就是把一个独立的函数API作为‘子文档’，保证检索的精确性；同时保留它与所属的整个模块页面（父文档）的关联，确保LLM在生成答案时，拥有最完整的上下文。
PyTorch核心的torch.nn模块
在最开始我使用稠密向量，