首先，空间智能到底是什么？
我认为，可以用不是空间智能，但现在却很普遍的大语言模型来对比
为什么大语言模型不是空间智能？ 
为什么他没有理解空间？
额， 技术上说， llm学习的仍然是数据的规律 然后输出一堆，规律的数据，这是恰巧这些规律的数据，我们人类能看懂。
那这个世界究竟是怎样的？如何影响这个世界，恐怖llm都是根据学到的序列数据 通过规律摸索的。

但我好奇了， 空间智能难道就不这么做吗？ 人类对空间的感知，不也根据数据吗？
博客讲，

“一种能够真正理解并赋能人类创造者的 AI—— 无论是学习分子化学复杂概念的学生、构思空间的建筑师、构建世界的电影创作者，还是渴望沉浸式虚拟体验的任何人 —— 这一承诺仍未兑现”

嗯，感觉，核心还是在，交互上。
llm确实没有能赋能我们，交互的能力
现在的agent仍然是根据llm嘛 感觉  仍算有点拙略

“而婴儿在还未学会说话的数月甚至数年中，正是通过与环境的嬉戏互动来认识世界。所有这一切都在无意识间、自动地完成 —— 这种流畅性，是机器至今尚未具备的。”

或许这一场景，才是空间智能想要达到的 
就是在目前智能的眼中 我们的世界是冰冷的 甚至 一维的 仅仅有数据， ，我觉得可以想想 我们的眼睛看东西，看不出3d的感觉 看任何东西都像照片  就是把空间感给去掉  我相信 这时的人类 也变得不智能了


“当科学家与发明家需要操纵物体、想象结构、推理空间关系时，正是空间智能推动了人类文明的跃进 —— 而这些都无法仅凭文字所捕捉。”
或许空间智能不能用言语表达， ， 真的   只能隐隐感受  确实  如果深度学习的数据 是源于“空间”（虽然我暂时无法想象）而不是文字转化的数字序列  也许真的不一样。
和人一样  一个人光读理论书 不去看不去听不去感受 能“智能”吗 


"人类对世界的理解是整体性的 —— 不仅关乎我们「看见了什么」，还包括事物在空间上的关系、它们的意义以及彼此的关联。**通过想象、推理、创造与互动来理解世界，而非仅仅依赖语言描述，这正是空间智能的力量**"

到底为什么  目前的多模态模型  不能够去做到这些呢？  把视频、图片变成序列送入模型中，为什么不能诞生“空间智能”呢？ 
李飞飞只是说 他们效果不好  但为什么效果不好呢？ 是不是业界学术界普遍有这个问题？




- 一个视频，对于MLLM来说，本质上是一系列高维向量（帧）的时间序列。模型学习的是这些向量序列中的**统计相关性**。例如，它观察到“一个球在上方的帧”之后，通常会跟着“一个球在下方的帧”。它学会了这种像素层面的模式转换。
    
    但是，它**没有**也**无法**从这种被动观察中，抽象出背后的物理规律：
    
    - **物体恒存性 (Object Permanence):** 它不知道视频中的“球”是同一个实体，只是位置变了。对它来说，每一帧都是一个全新的、需要被编码的向量。
        
    - **因果关系 (Causality):** 它不知道球下落是因为**重力**，也不知道如果有一个平面挡住，球就会**反弹**而不是穿过去。它只知道数据集中反弹的视频序列模式，不知道其背后的因"因果"。
        
    - **三维几何 (3D Geometry):** 它看到的是2D投影。当一个物体旋转时，它看到的是一系列形状和光影不断变化的2D图像。它很难建立一个内在的、统一的3D模型，来解释所有这些2D视图都只是同一个刚体在不同姿态下的投影。
        
    
    这就是为什么它们在需要“理解”几何和物理的任务上表现很差。
    
- **空间智能：主动的世界模拟器**  
    空间智能的目标，不是去“识别”一个球下落的视频，而是建立一个关于“球”和“物理”的内部模型，这个模型可以**预测（模拟）**：如果我把这个球放在这里，松手，它会怎么运动？如果前面有墙呢？如果是羽毛呢？
    
    这种能力，无法从被动的视频观看中高效学到。它必须通过**交互**来验证和修正模型。智能体需要“亲手”推一下物体，看看它是否符合自己关于“推动”和“惯性”的预测。如果不符，就修正模型。纯粹的观察，无法提供这种带有明确因果关系的反事实数据。








State-of-the-art MLLM models rarely perform better than chance on estimating distance, orientation, and size—or “mentally” rotating objects by regenerating them from new angles   提一嘴，什么是 mentally rotaing objects？

They can’t navigate mazes, recognize shortcuts, or predict basic physics. AI-generated videos—nascent and yes, very cool—often lose coherence after a few seconds.
确实是局限  这是不是也是，transformer之父呼吁大家“放弃transformer”的原因？是在说 已经压榨够这个架构的性能了  需要新思想了？


下面，李飞飞正式引出她的构想模型
world models 世界模型 
几大特点：
- **生成在感知、几何与物理层面保持一致的世界**
- 跟真实视觉一样，“超级多模态”  无论是图像、视频、深度图、文本指令、手势还是动作，世界模型都应能够预测或生成尽可能完整的世界状态
- **根据输入的动作生成下一个世界状态**。生成与先前世界状态、预期目标（若有）、语义含义、物理规律及动态行为相一致的输出。


能感受出 相较于语言这样一维、顺序性的信号，对「世界」的表征在维度与复杂度上要庞大得多
但是 我目前还真的想象不到 世界的表征 不用数字和向量表示 能用什么表示？ 而只要用数字和向量 我都感觉是 一维的 顺序的信号











啊，李飞飞似乎接下来就来解答我疑惑了

**1、一种新的通用训练任务函数**：

为世界模型定义一种像 LLM 中的「下一 token 预测」那样简洁优雅的通用任务函数，一直是该领域的核心目标之一。然而，由于世界模型在输入与输出空间上的复杂性，使得这种函数的构建本身极具挑战。尽管仍有大量未知有待探索，但这种目标函数及其对应的表征方式，必须能够反映几何与物理规律，体现世界模型作为联结想象与现实的基础性表征体系的本质特征。

嗯... 我们通过自回归“预测” 倒逼LLM学会人类的语言  现在要找任务，去间接训练模型学会世界的样子！




**2、大规模训练数据**：

  
训练世界模型所需的数据远比文本更为复杂。好消息是，大规模数据源已经存在。互联网上海量的图像与视频，提供了丰富且可获取的训练材料，真正的挑战在于如何研发能够从二维图像或视频帧（即 RGB 信号）中提取更深层空间信息的算法。过去十年的研究表明，在语言模型中，数据量与模型规模之间存在明确的「scaling laws」；对于世界模型而言，关键在于构建能够在相似规模上充分利用现有视觉数据的架构。

此外，高质量的合成数据，以及诸如深度信息与触觉信息等额外模态，也将在训练过程中的关键阶段发挥重要作用。但要实现这一目标，我们仍需更先进的传感系统、更稳健的信号提取算法，以及更强大的神经模拟方法。

无论是啥ai 都是数据非常重要啊 我还是好奇 数据的用法 


**3、新型模型架构与表征学习**：

  
世界模型的研究将不可避免地推动模型架构与学习算法的革新，尤其是在超越当前 MLLM 与视频扩散模型范式的方向上。现有方法通常将数据离散化为一维或二维序列，这使得一些简单的空间任务变得不必要地困难 —— 比如统计短视频中独特的椅子数量，或记住一个房间一小时前的样子。替代性架构可能带来突破，例如具备三维或四维感知能力的分词、上下文和记忆机制。


ok！这就是我想的， 也许在空间智能里面，真的要突破“transformer”这个架构 



后面的文字是一些未来展望
总之，说的是如果ai真的能完全理解世界，如何为我们赋能？
其实好想象，能理解世界就能与我们更好的交互了  

最后结语
“真正激励我的，仍然是图灵在 75 年前提出的那个问题背后的精神。我依然与他一样，怀抱着对智能的惊奇与敬畏。正是这种好奇与挑战的魅力，让我每天都为空间智能的探索而充满动力。”
也是激励了我，我也理智成为这种好奇驱动，兴趣驱动，去探索，去幸福自己，造福人类。 加油！

