除了格式和Loss Mask，处理多轮对话时，你还会遇到三个在单轮微调中不那么突出的问题：

#### **3. 数据处理挑战：上下文长度管理 (Context Length Management)**

- **问题**：多轮对话很容易变得非常长，经常会超过模型的最大上下文窗口（如4096 tokens）。怎么办？
    
- **策略：截断 (Truncation)**。必须丢掉一部分历史对话。关键在于**从哪里截断**。通常是**从对话的开头开始丢弃**，保留最近的几轮对话，因为它们对生成下一轮回答更重要。这是一个非常关键的数据预处理步骤。
    
- **优化：数据打包 (Packing)**。反过来，如果很多对话都很短，直接padding会浪费大量计算。可以将多条**独立的**短对话拼接（pack）成一个长的序列，用EOS (End-of-Sentence) Token隔开，塞满一个上下文窗口，以提升训练效率。
    

#### **4. 角色扮演挑战：系统提示 (System Prompt)**

- **问题**：我们通常希望模型有一个固定的“人设”，比如“你是一个乐于助人的AI助手”或“你是一个专业的法律顾问”。
    
- **策略**：在对话的最开始，插入一个特殊的**系统提示**。这个System Prompt也需要遵循模型的格式，并且在计算Loss时，它**总是被掩码掉的**。它只作为全局的指令存在。
    

#### **5. 评估挑战：多轮一致性 (Multi-turn Coherence)**

- **问题**：如何评估一个多轮对话模型的好坏？
    
- **挑战**：单轮对话，我们看回答是否准确即可。多轮对话，我们还需要评估：
    
    - **上下文理解**：模型有没有正确理解前面几轮的信息？
        
    - **逻辑一致性**：后面的回答会不会和前面的回答自相矛盾？
        
    - **指代消解**：当用户说“它怎么样了？”，模型知不知道“它”指的是前两轮提到的“那个项目”？
        
    - 这使得评估变得更加复杂，往往需要人工评估或者更复杂的自动化评估方案（如用GPT-4打分）。
        

### **面试官视角下的完美回答**

当面试官问：“如果要你来负责一个多轮对话模型的微调，你会关注哪些点？”

你的回答可以这样组织：

“首先，我会聚焦于两个最核心的环节：**对话格式化**和**损失掩码**。

1. **格式化**：我会严格遵循基座模型定义的Chat Template，使用特殊的Token来清晰地界定用户和助手的角色，以及对话的轮次。确保所有数据都转换成这种一致的格式是成功的第一步。
    
2. **损失掩码**：在计算损失时，我会将所有用户输入、历史对话以及System Prompt的部分在label中设置为-100，确保模型只学习生成当前轮次的助手回答，专注于扮演好自己的角色。
    

在此基础上，我还会处理几个关键的工程和评估挑战：  
3. **上下文管理**：对于超出模型最大长度的对话，我会采用从头部截断的策略，保留最新的上下文。对于大量短对话，我会考虑使用数据打包（Packing）技术来提高训练吞吐量。  
4. **系统提示**：为了让模型有人设和遵循全局指令，我会在对话开头统一添加System Prompt。  
5. **评估**：除了评估单轮回答的质量，我还会特别设计评估方案，来考察模型在多轮对话中的一致性、上下文理解能力，确保模型不会‘聊着聊着就忘了’。”