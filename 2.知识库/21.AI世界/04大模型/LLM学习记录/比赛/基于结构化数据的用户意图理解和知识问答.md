# 重构赛题
我们拿到一个数据
每一行如下所示

| 车次      | 始发站 | 终到站 | 到点    | 开点   | 候车厅            | 检票口 | 站台  |
| ------- | --- | --- | ----- | ---- | -------------- | --- | --- |
| K4547/6 | 成都西 | 佳木斯 | 23:40 | 0:12 | 综合候乘中心，高架候车区西区 | 1B  | 2   |


这里面包含了很多信息，但不是用自然语言描述的，而是用表格描述的！
我们平常用大模型大多都是给它提供自然语言数据，一段话，论文啦... 
本次赛题是用结构化数据，这也是本次比赛的命名由来

## 核心思路
结构化怕大模型看不懂，那就变自然语言呗！自然语言进行有监督微调，大模型就看懂了
不过变的方式，要变成下面的qa对，这是微调所要求的格式


```
{"instruction": "Z152次列车的终到站是哪里？", "output": "Z152次列车的终到站是北京西。"}

```

## 难点
比赛要求微调后的大模型，
应具备自然语言处理（NLP）能力，能够理解用户自然语言问题中的意图（如查询始发站、终到站、检票口等），以支持多种问题类型，例如：

- **单字段查询**：如“Z152次列车的终到站是哪里？”
- **多条件筛选**：如“在综合候乘中心候车、发车时间晚于08:00的列车有哪些？”
- **跨行计算**：如“从兰州到北京西的列车中，哪趟运行时间最短？”
- **时间推理**：如“K420次列车在兰州站的停留时长是多久？”
- **复杂时间范围过滤**：如“在'综合候乘中心'，到点时间介于06:00至08:00之间且站台为2的车次有哪些？”
- **缺失数据处理**：如“检票口为'5B'且开点时间缺失的车次有哪些？”
- **复杂单位换算**：如“K2095/8次列车的开点时间为05:51，若延误1小时15分钟，新的开点时间是几点？”

模型的输出应该是包含数值结果、文本描述及必要推理步骤的结构化回答，能够直接展示提取的指标和相关信息

这样势必对qa对要求很高

如何构造高质量qa就是核心

问题生成：

# 数据处理


| 车次      | 始发站 | 终到站 | 到点    | 开点   | 候车厅            | 检票口 | 站台  |
| ------- | --- | --- | ----- | ---- | -------------- | --- | --- |
| K4547/6 | 成都西 | 佳木斯 | 23:40 | 0:12 | 综合候乘中心，高架候车区西区 | 1B  | 2   |

先将时间标准化为datatime格式，以方便计算
首先可以新加一列运行时间，这个运行时间由我们自己数据处理出来。
如

| 车次      | 始发站 | 终到站 | 到点    | 开点   | 候车厅            | 检票口 | 站台  | 运行时长（分钟） |
| ------- | --- | --- | ----- | ---- | -------------- | --- | --- | -------- |
| K4547/6 | 成都西 | 佳木斯 | 23:40 | 0:12 | 综合候乘中心，高架候车区西区 | 1B  | 2   | 32.0     |

# qa对构造
基于
- **单字段查询**：如“Z152次列车的终到站是哪里？”
- **多条件筛选**：如“在综合候乘中心候车、发车时间晚于08:00的列车有哪些？”
- **跨行计算**：如“从兰州到北京西的列车中，哪趟运行时间最短？”
- **时间推理**：如“K420次列车在兰州站的停留时长是多久？”
- **复杂时间范围过滤**：如“在'综合候乘中心'，到点时间介于06:00至08:00之间且站台为2的车次有哪些？”
- **缺失数据处理**：如“检票口为'5B'且开点时间缺失的车次有哪些？”
- **复杂单位换算**：如“K2095/8次列车的开点时间为05:51，若延误1小时15分钟，新的开点时间是几点？
**时间推理**，**缺失数据处理**，**复杂单位换算**的qa对构造就不说了
## **单字段查询**
- 每个字段有多个问题模板（增加多样性）
- 答案模板统一格式
1. `target_col = random.choice(['终到站', '检票口', '站台', '候车厅'])` → 假设选中'检票口'
2. 检查 `检票口` 是否非空 → 是的，继续
3. 随机选择问题模板 → "我该去哪个检票口等{车次}次列车？"
4. 获取答案模板 → "{车次}次列车的检票口是{检票口}。"
5. 填充模板：
    - 问题：我该去哪个检票口等G1234次列车？
    - 答案：G1234次列车的检票口是A01。
其中，填充使用的是python字符的方法，format_map

```python
# 基本用法
template = "我的名字是{name}，今年{age}岁"
data = {"name": "张三", "age": 25}
result = template.format_map(data)
print(result)  # 输出：我的名字是张三，今年25岁
```
## **多条件筛选**
1. 随机创建筛选条件，random时间与候车厅列表
2. Pandas执行筛选，找到准确答案
3. 构造问题
4. 构造答案

```python
 train_list_str = ",".join(result_df['车次'].astype(str).tolist())

  answer = f"在'{hall_condition}'候车且发车时间晚于{time_condition}的列车有：{train_list_str}。"
```
## 跨行计算
1. 先标记出哪些站到站有多列车
```
eligible_groups = [name for name, group in grouped if len(group) > 1]
```
2. 随机选择一组始发和终到站
3. 找最值和生成QA
## **复杂时间范围过滤**
1. 随机创建筛选条件，random时间
2. datetime.time对象进行筛选

# 存在问题
我现在已经做完了数据。并微调了，但得分不够理想。我认为问题在于这些，首先，每一个类型生成的答案数量不一样，比如generate_missing_data_queries最多只能生成13条数据，而**单字段查询**：如“Z152次列车的终到站是哪里？”有219 条单字段查询QA，毕竟一共219行。 其次，虽然比赛这么说了
- **单字段查询**：如“Z152次列车的终到站是哪里？”

- **多条件筛选**：如“在综合候乘中心候车、发车时间晚于08:00的列车有哪些？”
    
- **跨行计算**：如“从兰州到北京西的列车中，哪趟运行时间最短？”
    
- **时间推理**：如“K420次列车在兰州站的停留时长是多久？”
    
- **复杂时间范围过滤**：如“在'综合候乘中心'，到点时间介于06:00至08:00之间且站台为2的车次有哪些？”
    
- **缺失数据处理**：如“检票口为'5B'且开点时间缺失的车次有哪些？”
    
- **复杂单位换算**：如“K2095/8次列车的开点时间为05:51，若延误1小时15分钟，新的开点时间是几点？ 
但问题不可能严格按照他举的例子，我们生成的数据算是严格按照举的例子生成了。
对于**单字段查询**、**跨行计算**、**时间推理**、**缺失数据处理**来说还好，因为问题的总数一定是有限的，模型完全可以“背题”。那对于**多条件筛选**：如“在综合候乘中心候车、发车时间晚于08:00的列车有哪些？”我们只能随机生成qa对，随机400条都可以，但就好像押题一样，似乎不会让模型真正学会自己推理
如果微调数据集里面有这个例子的qa对，那测试集问题如果是
“在'综合候乘中心'，到点时间介于06:00至08:01之间且站台为2的车次有哪些？”模型能回答对吗？
包括**复杂单位换算**：如“K2095/8次列车的开点时间为05:51，若延误1小时15分钟，新的开点时间是几点？    
也是这个问题。
# 修改方向

把原本脚本式生成的qa对，改成字典
用一个精心设计的Prompt，让LLM基于这些字典转化为**大量、多样化、自然的QA对**
为了比赛中**响应时长与效率优化**，所有回答的核心信息必须与“标准答案”一致，并且语言要尽可能地简洁、直接，避免任何不必要的寒暄或修饰（写入prompt） 
从LLM生成的庞大QA池中，**采样**出一个**最终的、各类别数量均衡**的训练集

# 开始修改

问题：for __ in range(target_num) 不能准确把控模型生成，那就whilel len(final_qas) < target_num:

```python
content_str = data['choices'][0]['message']['content']

        # 模型有时会在JSON前后包含 ```json ... ```，需要提取

        if '```json' in content_str:

            # 修正前: .split('```json')[1].split('```')  --> 返回一个列表

            # 修正后: .split('```json')[1].split('```')【0】--> 返回列表的第一个元素（字符串）

            json_part = content_str.split('```json')[1].split('```')[0]
```
大模型的多样性生成，保证了数量均衡、**大量**
提示词工程，保证了**响应时长与效率优化**、问答对的不同模式

对于**多条件筛选**、**复杂时间范围过滤**、**复杂单位换算**的押题感觉仍然严重，大模型没有解决。
目前只能认为靠数据量让模型内化成知识，新问题出来自己能解决；

还有同一问题，通过大模型构造不同语气、语序的问题，是不是也能让模型稍微学会推理而不是背题呢？
