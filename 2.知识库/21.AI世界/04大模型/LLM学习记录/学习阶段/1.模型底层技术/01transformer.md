# 之前怎么处理
- RNN：顺序依赖结构，但当序列非常长时，会遗忘之前信息
- LSTM：比RNN稍微好点，但仍然会遗忘
 一个很长的句子：“小明住在一个美丽的沿海城市，那里夏天游客很多，......（省略100个字）......所以他最喜欢的运动是**冲浪**。”
怎么让模型看到看到冲浪，能想到”沿海“和他相近呢？
这是两个词，词向量位置接近，那就意思接近
所以在embedding时，通过某些方法就设计得让这俩词的词向量接近

但仍然很死板啊，如果”冲浪乐队在沿海城市开派对“，模型就会把这个乐队的名字和沿海相关起来，但乐队名字和沿海没关系！

# transformer的思想

首先，我们是先Q矩阵与各个词的K矩阵点积，积出来的结果就是各个词的分数，然后讲分数经过softmax函数，变成0-1的数，我们称为权重  比如上面例子，当我想计算沿海的词向量，冲浪的权重是0.9 ，小明的权重是0.01，然后我们权重乘各个词的v矩阵，相加，就是最终沿海的词向量 


- **旧方法（Embedding）**：是的，它就像一个预先训练好的“字典”。无论“bank”出现在哪个句子里，它从字典里查出来的初始词向量 [0.5, 0.2, -0.9, ...] 都是**固定不变的**。这是一种**上下文无关**的表示。
    
- **新方法（Attention）**：Attention机制的目的，就是要在初始词向量的基础上，**为每个词生成一个全新的、融合了当前句子上下文信息的向量**。
    

所以：**“同一个词，在不同句话中（经过Attention之后）词向量都不一样”**。


> “苹果公司发布了新手机。” -> 这里的“苹果”向量会富含“公司”、“科技”的意味。  
> “我晚饭吃了一个苹果。” -> 这里的“苹果”向量会富含“水果”、“食物”的意味

<font color="#f79646">然后qkv从哪来，应该就是从词嵌入向量来，要加工吗？ 当然了，不然每个词的qkv长一样肯定不行，如何加工我忘记了</font>

1. 我们准备**三块不同**的、可以学习的权重矩阵，我们叫它们 W_Q，W_K 和 W_V。
    
2. 当一个词的初始嵌入向量 E 进来后，我们用它分别去乘以这三个矩阵，就得到了三个不同的向量：
    
    - Q = E * W_Q
        
    - K = E * W_K
        
    - V = E * W_V

也就是说，这个W_Q 非常万能，乘任何一个词的初始embedding，得出的结果，都能表明那个词的query意图。 比如W_Q就是不变，它乘’猫‘ 得到的Q向量，在将来对”毛“”宠物“这些词的K矩阵进行相乘时，得分一定高，同样的W_Q矩阵，去乘'苹果’得到的Q向量，在将来对‘吃’‘公司’这些词的K矩阵进行相乘时，得分也一定高？ W_K也是的，乘任何一个词，都能把这个词的含义表现出来，将来有和这个词相关的Q矩阵过来时，这个K矩阵就能做到与Q矩阵结合后分高？ 是这样吗？ 看起来K和Q是双向奔赴的感觉

# 多头注意力
当然，我们嘴上说搞个万能的W_Q，但不是想搞就能搞的。
怎么样去造一个这么万能的W_Q呢?  


1. 我们不只有一套 W_Q, W_K, W_V 矩阵。
    
2. 我们创造出**多套**（比如8套）**完全独立的** W_Q, W_K, W_V 矩阵。每一套，我们就称之为一个**“头” (Head)**。
    
    - Head 1: 有 W_Q1, W_K1, W_V1
        
    - Head 2: 有 W_Q2, W_K2, W_V2
        
    - ...
        
    - Head 8: 有 W_Q8, W_K8, W_V8
        
3. 当处理“狐狸”这个词时，它的初始词向量会**同时**被送到这8个“头”里，进行8次**并行**的、我们之前讨论过的Attention计算。
    

由于每个“头”的权重矩阵是独立初始化、独立训练的，它们会逐渐“学会”关注不同类型的关系。

- **Head 1** 可能经过训练后，发现把“狐狸”的 Q 和“棕色”的 K 匹配起来，能有效降低翻译或预测的错误，于是它就成了一个**“颜色关系专家”**。
    
- **Head 2** 可能发现，把“狐狸”的 Q 和“跳过”的 K 匹配起来效果最好，于是它就成了**“主谓关系专家”**。
    
- **Head 3** 可能专门关注代词关系，等等。

完了，先把这些头拼接，拼接就多维度了对吧，然后再经过线性层，进行降维！
降到原来的维度，这样模型就能理解了！

# FFD
<font color="#f79646">但是再往深会出现什么情况？</font>
<font color="#f79646">信息丢失</font> 
如果我们直接用 Z 作为输出，就等于**强迫**模型必须通过注意力模块。

而如果我们使用残差连接，也就是计算 X + Z 作为输出，就给了模型一个**选择权**。

这个加法操作 X + Z 意味着，我们新设计的注意力模块，只需要学习对原始信息 X 进行**补充和修正**就够了。它不用从头学习所有信息，只需要学习**增量**。如果注意力模块发现自己没什么用，它只需要学着输出一个接近于零的向量 Z，那么 X + Z 就会约等于 X，原始信息就无损地流向下去了。

接近进行layernorm 把数据拉平稳
