# 下游任务
就算把训练好的模型应用到具体任务

# llm 发展历程
- 统计语言模型
- NLM，word2vec：神经语言模型，引入词向量，抛弃独热编码
- 预训练语言模型，ELmo：lstm 学习语义；
# llm 关键技术概览
- 规模拓展。超多参数，超大规模，出现“涌现能力”
- 高效预训练。大规模分布式训练算法，3d 并行、、分布式框架，训练软件如 deepspeed。gpt4 构建了较少算力开销的性能
- 能力激发。微调无法向大模型注入新的知识，但能帮大模型更好的理解知识。还有包括提示词等特殊表达形式诱导大模型对复杂任务的求解能力
- 人类对齐。监督微调对齐，使 llm 输出的内容更符合人类的预期。如 dpo 算法，简化 rlhf 优化过程


llm 上下文学习的能力的涌现，仍缺乏形式化的理论解释
# 大语言模型和传统语言模型的区别
大语言模型如 gpt，llama，是超大规模，十亿万亿参数规模，预训练后的语言模型。不仅数据与参数更多，方法也比传统模型更加优化，更加复杂，进而帮助模型涌现出理解能力、求解任务能力。

# bert
训练的目标是完形填空，它能很好的理解文本。gpt 训练目的是预测下文，他能很好的创作
# 指令微调
经过大规模预训练后的大模型，好似刚毕业的学长，通用知识有但专业知识还是不咋地。所以需要指令微调（有监督微调）
# 强化学习
强化学习对齐方法 RLHF
# 拓展法则
### **一句话总结**

- **KM法则**：堆参数！→ **Chinchilla法则**：不，堆数据！→ **现在**：数据和参数都要狂堆，但数据更重要！

（就像做饭：KM说“锅越大越好”，Chinchilla说“食材更要新鲜”，现在发现“两者都得顶配，但食材优先”。）