博客中的公式，没有细究。比如 rnn 不能序列长距离的公式推导，而lstm 可以的公式推导
还有 attention 中 softmax 运用使数据变极端的公式推导




# 词向量 **Word Embedding**
独热编码效率低，空间大，且不能体现关联度
那我们给独热编码乘一个随机矩阵，这个矩阵被神经网络训练好后，原本的【000 1】这种低效的向量就变成【286731】这种，这下能体现关联度了
<font color="#e36c09">如何训练的？</font>
以词的判断正确概率越来越高作为标准，通过训练集，优化矩阵参数和 layer 的参数

<span style="background:rgba(173, 239, 239, 0.55)">我们模型的发展就是为了让这个“词向量”更精准</span>

# Word2Vec
为了得到词向量的神经网络
## cbow
通过词的上下文，预测这个词是啥
## skip-gram
通过词，预测上下文是啥

这里比较对后面有参考意义的是 cbow 方法。还要注意的是，原先的基础语言模型，NNLM，是通过上文预测下文，双层感知机，有 tanh 激活函数。而 cbow 没有使用 tanh

无论是啥，目前学到的模型来说，缺点都是多词一义的情况无法处理！（会变成不同的词向量，<font color="#e36c09">但相关性应该挺高吧？</font>）一词多义更无法处理（明明是不同的词义，却是相同的词向量）

对于cbow 也是，无法提取上下文信息，即语境，<font color="#e36c09">为啥？不是通过上下文预测 q 矩阵的吗</font>？

# RNN （Recurrent Neural Network）
获取文本时序特征，但只能短时序

![[day2-1744347251510.jpeg]]
# LSTM
捕捉远时序特征

# ELMo
词的词向量，借助 lstm 工具加了上下文信息。使得一词多义，也多向量
原本的模型方法只有一个词，词只有一个独热编码加一个专属矩阵。所以说一词虽然多义，但表现出来的向量都一样

# attention
人眼看一张图的时候因注意力不同而有重点，我们模仿这个注意力集中，只强调一张图片的某一部分是重要的。
人-->观察者信息 q
模型要注意这--》这些文本信息 k对观察者信息重要
qk'相乘得相似度，<font color="#e36c09">然后输入 softmax，得到一个概率？</font>
<font color="#e36c09">softmax 之前要缩放才会避免梯度消失，极端数据这种情况</font>
答：这和指数有关
q，k，v，q是观察者，就是另一个信息，v是此刻眼前的信息，k是眼前信息中值得q观察的部分，一般与q相关性很大。<font color="#e36c09">但我还是不理解这些到底有啥用？attention是来解决什么问题的？人们怎么知道这个图片中要注意的是什么？</font>
答：q 先与 k 相乘，得到相似度 A，A 与 V 相乘，相当于给 v 分了权重，在这个原始 attention 中，k 是被训练出来的，自带标签
### 🖼️ **图像注意力的实际案例**

假设模型需要描述图片："一只猫蹲在键盘上"

#### **注意力决策过程**

1. **生成Q**：当需要输出名词"猫"时
    
    - Q编码了"寻找有动物特征的主体"
2. **扫描K**：
    
    - 图像区域1的K：毛茸茸纹理 + 三角形轮廓
    - 图像区域2的K：矩形结构 + 字母纹理
3. **计算权重**：
    
    - 区域1的K与Q相似度最高 → 权重0.9
    - 区域2的K相似度低 → 权重0.1
4. **聚合V**：
    
    - 用0.9×区域1的V（高分辨率猫特征） + 0.1×区域2的V（键盘边缘）

#### **可视化证据**

使用Grad-CAM技术可观察到：模型在生成"猫"时，注意力热图聚焦在猫头区域，验证了权重分配的正确性。
## self-attention
attention 的子集了属于是
一大特征是，每个词都有自己的 q，v，k，不像原始的 attention主客分明。那每个都有图啥呢？图跟每一个词，都能跟这个句子中的其他所有词利用矩阵做相关性计算！那么每个词就真正的与语境结合起来。最后 x 变成 z，这个 z 就是有更多语境和语义特征信息的 z

## MUlti-Head Self-Attention
在自注意力机制的基础上，把 x 分为 8 份！变成 8 个 z，8 个 z 拼接后降维