# 解释一下langchain Agent的概念
先说langchain的概念:langchain是一个让大模型应用的框架，让大模型的智能应用到具体的任务上，具体实现的功能就是些读取文件、数据，调用不同的模型，组合不同的功能。
agent是能对现实世界产生识别与交互的大模型应用。人类给他一个目标，他通过现实中的反馈，和大语言模型的智能，不断修正行为，不断接受反馈，最后于现实环境交互达到目标。agent是切切实实帮助人落实任务，而不是像正常的大语言模型提供思维上的指导。
# langchain的六大核心组件和作用
第一个，Model I/O
包装聊天模型，管理提示词模板，还有提供对输出的修改如转换格式、增加符号等
第二个，Retrieval，数据加载
读取文件的dataloader，各个格式的表格、文件，pdf。接着是文档分割器，可以按字符、按token等，再就是嵌入模型，将文件转化为向量，还有向量库的接入，正式存储模型，还有检索器，读取向量库里的向量
第三个，chains
也被称为langchain语法表达式，用于将各个组件组合，调用
如提示词模板 | llm | 输出解析器
第四个，memory
使用Memory组件来存储历史信息
第五个 agent
在第三个功能chain的基础上，串联工具。使大语言模型与更多工具集成，实现更多复杂功能。这里仍是以chain功能为基础的。但与原始chain的静态相比，agent是动态的，llm有自行决策权，调用工具权
第六个 callback
记录日志、监控性能

# langchain有哪些优点和明显的缺点

优点：吧复杂功能拆分成了独立模块，这样做项目的时候能将一个一个独立模块累加起来，可以快速开发，将大模型落地
缺点：抽象过度，概念繁多，版本一直迭代。在实际生产环境，特别是高并发时，框架层本身可能带来额外开销（延迟、资源消耗）。如何优化性能、保障稳定性是个问题

# langchain有哪些替代方案
llamaindex框架，针对文档检索、索引更加高效，与langchain对比更轻量、针对性更强


# 什么是检索增强生成

总结：rag，一种结合信息检索和文本生成的技术框架。在模型生成时，不仅依赖于模型初始的预训练能力与用户的问题文本，还会从数据库里检索与用户问题相关的文本，当作上下文，同用户的问题一起输入到大模型，最终让大模型生成更准确、与用户问题更相关的回答

# 在做知识增强检索时，文本切分有哪些方法
规则切分，按预设的字符数或者说token去分割、滑动窗口允许相邻块之间部分重叠得切割
语义切分，通过模型计算句子的相似度，动态合并相似内容
也可以让llm自身去切分，比如设定关键词，让大模型提取


# 目前主流的中文向量模型有哪些？

**BGE系列（北京智源）**百川-Text-Embeddings**
# 相比模型直接生成，RAG的优势是什么？
当模型输入不仅有用户文本，还有检索到的额外补充资料与用户文本一起当作输入时，模型的输出会更加精准

# SELF-RAG是什么，SELF-RAG如何提升大型语言模型的质量和准确性？
self-rag 引入**Reflection Tokens**
模型首先生成 `[Retrieve]` 或 `[No Retrieval]` 令牌，判断当前是否需要外部知识
最终按需检索。相比传统RAG固定检索文档，Self-RAG仅在必要时检索，降低无效调用，对于知识也是主动筛选高相关文档
# RAG和微调的区别是什么?
从技术上说，rag是从外部知识库检索相关文本，拼接为上下文输入LLM，而改变输出。微调是在垂直领域上更新模型参数，而改变输出。
rag不需要重新训练模型，他只是拓展知识边界，好比给一个c++工程师看java的书，现场让它回答java知识。而微调是直接让c++工程师花时间花精力学java，让他变成java工程师，去回答问题。rag比较灵活，微调把模型定死。

# 什么是 Graph RAG?
是结合知识图谱与检索增强生成的技术框架，采用**图遍历算法**，多跳推理，提供证据链，提供全局视角，给出的回答更加全面，当然产生答案的耗时也比较高



