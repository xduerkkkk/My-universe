吴恩达提示词
这是23年的课，课很短，是面向chatgpt的使用！
## 格式方面
- 符号引用：自己若引入文本，用上分隔符号把文本框起来，模型对符号引用更敏感，而不是"下面是...."      deepseek对话是否会自动转换成符号引用格式？
- 格式输出：如果可以，让模型输出如"json格式"，"html"格式的文本 ，再举个例子，比起让模型说是或否，可以让模型引用"布尔值"，"01值"   不懂原理...其实我觉得不太实用，又不是人人程序员..后面探索一下
- 有的时候人类的思维链条是一瞬间的事，但对于大模型可能需要分步骤。就好像力扣刷题一样，把脑海中想到的步骤如程序般精密地拆分。在提示词中想好步骤。先...再...
- 小样本提示，给出好的示例
## 其他使用技巧
- 具体！让模型专注于某一个点，而不是泛泛而谈。这其实就是，跟ai对话之前，把自己的问题想清楚，自己到底需求是什么，细化问题。这个比较实用，但其实无论跟谁对话，只要目的是去解决问题，都要这样"细化"。
- 对于询问大模型对文字的感情倾向（如，你支持这段话吗） 大模型是倾向于"谄媚"的，这个问题直到2025也存在，记得几天前还看到李飞飞团队发表过类似文章。23年吴恩达给的prompt解法是，在这种情况下，让模型自己推理，然后把自己推理的东西和文字进行比较，再发表观点。不知道deepseek思维链是不是这样，但是deepseek也有谄媚效应呀?
- 提示词需要迭代，不断修改，需要有耐心才能找到自己的模板。对一个问题有模板了，就记录下来
- 一定要小心，模型具有幻觉，会虚构。技术上的原因很简单，看看模型是怎么训练的。现在的解决应该是搭建知识库？记得去年就有看过解决模型幻觉的文章，再了解了解。反正除非指定模型输出在提供文本内，否则要谨慎求证
- 将文章的总结，用"文章的提取"替代
