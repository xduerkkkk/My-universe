torch.save是生成一个path文件，具体参数看填入的字典。其中model.state_dict()是必不可少的。 torch.load能加载这个path文件，加载出来也是字典，所以要提取出['model']这个key,然后再加载。
 **必须先在代码中创建一个模型的实例**，比如 model = MiniMindForCausalLM(config)。模型框架（“骨架”）必须先被建立起来。
 模型加载好后，可以使用 .save_pretrained方法，将模型变成huggingface格式，是safetensors后缀，为模型主体。要重新加载模型，就用frompretrain，我理解的对吗？ 那lm_eval框架加载模型是用什么方式呢？ 为什么出现这个报错呢Starting evaluation of ./my_pretrain_model_hf on tasks: ['ceval-valid_marxism']
 - **加载 (.from_pretrained)**: AutoModelForCausalLM.from_pretrained("./my_hf_model") 是一个“工厂函数”。它的工作流程是：
    
    1. 进入 ./my_hf_model 目录，首先寻找并读取 config.json 文件。
        
    2. 从 config.json 中找到 model_type 这个字段（比如 "llama" 或者在你的情况里是 "minimind"）。
        
    3. 根据 model_type，它去一个内部的“注册表”里查找对应的模型类（比如 LlamaForCausalLM）。
        
    4. **自动创建这个模型类的实例**，并把权重加载进去。
        
- **总结**：这是**根据配置文件，自动创建骨架并填充灵魂**的过程，使用者无需提前在代码中创建模型实例。