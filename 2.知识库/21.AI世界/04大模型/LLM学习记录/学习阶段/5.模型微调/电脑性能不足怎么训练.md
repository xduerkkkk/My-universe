# 4bitQLoRA
原本每个参数16bit，通过数学算法，尽可能不丢失主要信息的情况下压缩到4bit
在这个基础上，再进行lora微调
具体的数学算法为：**正态分布映射**​：假设权重服从高斯分布，将权重缩放到 `[-1, 1]` 区间后，用 ​**4-bit NormalFloat (NF4)​**​ 数据类型表示
# 梯度积累
batchsize是每次模型处理的数据个数。显存不会自动释放，而是累积梯度直到执行 `optimizer.step()` 和 `optimizer.zero_grad()` 后释放。是可以人工控制的。按常理每处理一个batchsize显存就释放一次
因为显存少，所以每次batchsize设置的小是不得已的事。原本32个数据的batchsize训练完反向传播一次，现在为了达到原来的效果，4次batchsize的梯度累加后，再反向传播一次