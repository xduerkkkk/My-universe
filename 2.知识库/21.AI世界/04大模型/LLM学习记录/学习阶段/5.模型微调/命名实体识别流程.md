# 数据

```json

[ 
{ "id": 1, "name": "Alice", "age": 30, "city": "Beijing" }, { "id": 2, "name": "Bob", "age": 25, "city": "Shanghai" }, 
{ "id": 3, "name": "Charlie", "age": 28, "city": "Guangzhou" } 
]

```

```jsonl
{"id": 1, "name": "Alice", "age": 30, "city": "Beijing"} 
{"id": 2, "name": "Bob", "age": 25, "city": "Shanghai"}
{"id": 3, "name": "Charlie", "age": 28, "city": "Guangzhou"}
```
可以看到jsonl与json的区别就是没有数组括起来，也没有逗号
JSONL就是一行一个JSON对象的文本文件。

# 数据处理

```json
{'instruction': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {"entity_text": "南京", "entity_label": "地理实体"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出"没有找到任何实体". ', 'input': '文本:#电信狂欢月#电信517，湖南网厅四折！转发拿小米3咯！地址：[http://t.cn/8sesVRR](http://t.cn/8sesVRR)', 'output': '{"entity_text": "湖南", "entity_label": "政治实体"}'}

```
原本的数据集有instruction、input、output
我们期望喂给大模型的数据格式是，
input_ids attention_mask labels
对于本次任务，核心点是让模型”学会说出我们既定格式的话“
既然是学说话，我们给模型的input_id 不能仅仅是input的，还需要有output的 我们给模型输入的labels，只有output   也就是给模型的数据格式中，告诉它输入”文本＋答案“，标签是”答案“，这样子它才能学会。而不是输入”文本“，标签”答案“，这些它学不会
生成式任务（如指令回复、文本生成）的标准做法

```python
input_ids = [token_A, token_B, token_C]  # 包含 input + output
labels    = [-100,   token_B, token_C]   # 仅 output 部分参与损失计算

```

| **任务类型**​         | ​**input_ids 内容**​ | ​**labels 内容**​     | ​**适用场景**​         |
| ----------------- | ------------------ | ------------------- | ------------------ |
| ​**生成任务**​（如指令回复） | input + output     | output 部分（屏蔽 input） | 机器翻译、问答、摘要<br><br> |
| ​**分类任务**​（如情感分析） | input              | 分类标签（如 0/1）         | 文本分类、实体识别<br>      |
tokenizer处理数据，比如处理了数据集的`['input']` ，处理后的序列就已经有input_ids attention_mask labelsl了吗？  

| ​**字段**​         | ​**生成方式**​     | ​**默认值/示例**​        | ​**作用**​             |
| ---------------- | -------------- | ------------------- | -------------------- |
| `input_ids`      | 文本→Token ID 序列 | `[101, 234, 102]`   | 文本的数值化表示             |
| `attention_mask` | 自动生成掩码         | `[1, 1, 1]`（有效部分为1） | 标识有效Token位置（避免填充符干扰） |
| `labels`         | ​**需手动构造**​    | `[-100, 234, 102]`  | 训练目标（屏蔽输入部分）         |


最后是使用
`train_ds = Dataset.from_pandas(train_df)`
再对每个trainds map上我们的process方法的
`dataset[0]` 返回的是字典形式，所以可以用map

所以数据集格式的转变为：
`原始jsonl-----dataset_transfer函数：先构造messages列表，不断添加message字典--一一读取列表里的json，使用json.jump 重构数据为jsonl-----划分数据集，所以使用pd.read_json 转化为DataFrame进行划分-----使用Dataset.from_pandas 把DataFrame转化为dataset对象`

# 训练中的一些问题
`DataCollatorForSeq2Seq` 是干嘛的？
用来保证样本的长度一致
假设批次包含两个样本：

1. ​**样本1**​：
    - 输入：`"湖南电信促销"` → `input_ids: [101, 234, 102]`
    - 输出：`{"entity": "湖南"}` → `labels: [1234]`
2. ​**样本2**​：
    - 输入：`"南京市长江大桥"` → `input_ids: [101, 204, 305, 406]`
    - 输出：`{"entity": "南京"}` → `labels: [5678]`

​**DataCollator 处理后**​：

```python
{
  "input_ids": tensor([
      [101, 234, 102, 0],      # 样本1填充1位
      [101, 204, 305, 406]     # 样本2无填充
  ]),
  "attention_mask": tensor([
      [1, 1, 1, 0],            # 样本1掩码
      [1, 1, 1, 1]             # 样本2掩码
  ]),
  "labels": tensor([
      [1234, -100],            # 样本1标签（仅"湖南"参与损失计算）
      [5678, -100]             # 样本2标签（仅"南京"参与损失计算）
  ])
}
```
#### **Train Loss 与 Grad Norm 的关系**​

- ​**动态联动**​：
    - ​**Loss 下降但 Grad Norm 高**​：可能处于优化初期或复杂区域，需警惕梯度爆炸（需梯度裁剪）
        
    - ​**Loss 稳定但 Grad Norm 低**​：可能接近局部最优或陷入平坦区域（需增大学习率或检查数据）

    - ​**Loss 波动大且 Grad Norm 高**​：学习率过大或数据噪声多，需降低学习率或增加批量大小

**模型保存？**
如果我训练前模型的变量名叫model，那我训练后，在当前的python文件或ipynb文件中，使用model，是用的训练过后、参数改变的模型。如果想在别的地方使用我训练好的模型，应当在当前文件中使用torch.save(model,'finetuned_model.pth") 然后在别的地方使用model = torch.load(训练文件保存的路径）

`save_pretrained` 会生成 `pytorch_model.bin`（权重）、`config.json`（超参数）、`tokenizer.json`（分词器），而 `torch.save` 仅生成单一 `.pth` 文件，不包含模型结构信息

| ​**特性**​   | ​**`model.save_pretrained​**​                           | ​**`torch.save(model, ...）​**​                                                          |
| ---------- | ------------------------------------------------------- | --------------------------------------------------------------------------------------- |
| ​**保存内容**​ | 模型权重 + 配置文件（config.json） + tokenizer（可选）                | 仅模型参数（state_dict）或整个模型对象（含代码结构）                                                         |
| ​**加载方式**​ | 标准加载：  <br>`model = AutoModel.from_pretrained("./dir")` | 需重建模型结构：  <br>`model = MyModel()`  <br>`model.load_state_dict(torch.load("model.pth"))` |


**训练后模型预测/测试**
对预测函数，要把传入数据使用tokenizer序列化，再使用`model.generate` 预测出序列化张量 使用tokenizer.decode 把序列化张量再翻译出来即可