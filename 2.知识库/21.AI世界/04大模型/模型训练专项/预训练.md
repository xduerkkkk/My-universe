# 预训练的定义
如果我们把大模型想象成人，我们的目的，从事法律的人想培养出法律助手，从事医学的想培养出医学助手，这些助手都是经历过某一领域专业知识才可以，但在这之前，他们都有一个共性，就是接收过义务教育。
从婴儿到大学，所有人的义务教育都一样，要学习数学语文文理科的通识知识。
如果义务教育都没学好，直接上手专业知识是非常难的。
预训练就是这个义务教育阶段，我们给模型大量低成本的数据，模型初始是什么话都不会说的婴儿，通过监督学习，变成了会说话的，学习到知识”共性“的，大一新生。

这种注入大量人类语言知识的模型，通常称作基座模型。

# 预训练过程
首先，数据是纯文本。来源与非常广泛。
训练时的任务是，根据前面的文本词语预测下一个次元。 这一过程是不断适用attention机制的。 那传入的文本是完整的句子，我们怎么做到训练模型预测能力呢？
使用注意力掩码。


