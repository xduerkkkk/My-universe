# 核心机制
不管输入是一个句子一口气输入，还是一个字一个字输入
之前的RNN/LSTM 都是按顺序读入的。
attention机制呢？
无论送来长什么样子，我都拿你整个的向量（每个词向量拼接的）
一口气去乘三个不同的矩阵（也可以乘一个大矩阵待会分成三个）， 
变成q、k、v三个向量。
这三个向量，显然不同，但全部都是输入由linear变化的， 变化后的维度都是hiddensize，就是说三个向量内容不同维度相同。
 那他们不同的内容，都各司其职司的什么职呢？
 q向量，我们人为定义为查询向量（下面的定义都是人为定义，因为机器不能一开始就被定义”哦我要查询..“ 而是在漫长的训练中学习到的”哦原来我这个向量目的是查询“）
 这就好比”attention“的字面含义，对于目前的，我的整体的向量，假如我要生成下一个词，我到底要attention什么东西？ 蕴含在这个向量里。
 k向量，关键词向量， 我这个向量，到底有哪些关键的地方，别人要查询的时候能看到。 
 v向量，本身的含义，就朴素一点， 代表整个向量本身的值。可以把它理解为：“**如果**你决定要关注我，我这里准备好了一份**专门用于被提取**的信息摘要（Value向量）”。它不完全是原始词向量的“大小”，而是它准备好“贡献”给别人的信息。

ok，现在我们人工定义好了。 实际上，到底怎么去把整个句子向量计算出来呢？
关键的公式，就叫注意力点积。
Q向量与K向量做矩阵乘法（一般K向量做一下维度变换），含义就是， 我现在携带着我的问题（查询向量），去看看你值得注意的地方（键向量）。  最后的结果呢， 就是哪里真的需要注意！  或者叫，查询与键的相似度！ 你想找的地方，和我真的值得注意的地方，匹配吗？

现在我们暂时深入到代码层面，看看具体怎么”双向奔赴“的
假设我们的句子是”我爱人工智能“ 
共有六个字，Q矩阵就有六行，假设每个字的含义，我们要用4个信息来表示，那就是4列。
六行四列。专业一点，我们称，用一个**4维的向量**来表示”。Q矩阵的**每一行**，都是一个代表那个字/词的Query向量。
K矩阵呢，也是这个形状
下面我们矩阵相乘 Q@K^T
什么情况了？ 变成六行六列  行是”我爱人工智能“，列也是
那么我们那第一行来说 我字 对应着六列的我爱人工智能  
坐标1，1  是”我“对”我“的关注度 1，2 是”我“对”爱“的关注度 以此类推

ok 现在我们就完成了一个注意力矩阵。
现在再把v矩阵拿出来， v矩阵是啥形状？ QK一样的六行四列， 我们又拿这个注意力矩阵和v矩阵相乘 ，什么情况？ 
又变回六行四列了！什么含义？
我们刚才的注意力矩阵，叫关注度，但是你具体是什么值呢？
一个庞然大物，就算我关注度很小，到最后仍然会关注很多
一个小不点，就算我关注度很大，仍然会关注很少。
那么V矩阵就是看，这六个字目前大小都是怎样的！
我们现在的六行四列，其中的坐标1，1 就是”我“这个字，对所有字的关注度乘所有字本身的权重，再相加，得到的结果！  1，2 呢 也是！ 为啥，因为权重不是只有一个，权重是一行！
总而言之，最后得到的 矩阵的 第一行 就是全新的，”我“的 词向量， 和初始一样，仍然是4维，但维度里充满了整个句子的信息。 
可以看作是对**所有**Value向量的一次**加权平均**。注意力分数（经过Softmax后）就是那个“权重”。

- 比如，计算“我”的新向量时，如果对“人工”的注意力权重是0.8，对其他词都是0.05，那么新的“我”向量，其中80%的内容就是来自“人工”的Value向量，剩下20%由其他词的Value向量贡献。


## 补充
在上述过程中，我们qkv矩阵还可以通过分割维度来优化，那Q来说， 本来一个大Q向量关注某些东西，我们现在把大Q分成小Q，每个小Q都有自己要关注的地方，这就叫多头注意力。当然了，Q分割了，k和v也要分割，因为上述过程我们也看到了，三者维度一直是相同的，才能做矩阵乘法。  分割的代码非常简单，最简单pytorch分割维度，也就是我们并没有定义“这个头学这个，那个头学那个” 而是分割后，通过各自的训练，让他们自己涌现不同的注意力方式。
另外，在我们所谓的注意力权重，与V向量相乘前，要进行softmax， 把向量变成一个概率的向量！ 这不也正好，对应所谓“权重”二字吗？ 
但我们既然要用softmax，就要注意它的特性， 就是如果这一行有数字比别的都大很多 ，那它的概率就十分接近百分百，相当于把别人的权重都弄没了，
为了避免这种特性带来的权重损失， 我们再QK^T 矩阵相乘后， 除以一个根号dk，dk是上面说的，每一个字，想要蕴含信息的维度数，上面就是4维。 在实际应用中，最小也应该512吧，这个维度也叫hidden_state 也叫d_model,
我们理解 除以一个根号dk就是缩放数字，不要数字那么大。 那为啥偏偏是这个数？ 不是dk 不是dk的根号三次方？

“这个缩放因子sqrt(d_k)是为了**稳定训练过程**。论文作者从概率论的角度分析，假设Q和K的元素是均值为0、方差为1的独立随机变量，那么它们的点积结果的方差会等于d_k。这意味着，当d_k很大时，点积结果的数值范围会很大，这会导致Softmax函数进入饱和区，产生非常小的梯度，使训练困难。我们想让方差恢复到1，根据方差的性质，Var(X / c) = Var(X) / c² 通过除以sqrt(d_k)，可以将点积结果的方差重新缩放回1，使其与维度d_k无关，从而保证了数值的稳定性和梯度的有效性。
# selfattention与crossattention
只是说QKV是谁而来的。 只要QKV同源就是selfattention  不同源就是crossattention。
这个判断很简单，我们拿俩个情景说。
一个就是论文中的机器翻译模型， decoder和encoder内部，都是各自各自的序列，selfattention 直到encoder把处理好的向量 拿出来 给decoder时， 我们把这个向量当作,当作哪个向量来着 然后encoder的另外两个向量保留 那么此时就是crossattention
第二个是多模态的crossattention 传统diffusionmodel 是使用带crossattention的unet 让模型同时理解文字和图片 依旧是qkv不同源，不过分别怎么对应的？

机器翻译：
- **目的**: 在做完“内部反思”后，去**参考一下原文**，看看原文的哪些部分对生成当前这个词最有帮助。
    
- **Q, K, V的来源**:
    
    - **Query (Q)**: 来自**上一层（Masked Self-Attention）的输出**。这个Q代表了Decoder当前的需求：“基于我已经生成的词，我现在需要什么样的信息来决定下一个词？”
        
    - **Key (K) 和 Value (V)**: **全部**来自**Encoder的最终输出 (encoder_outputs)**。encoder_outputs是一个包含了原文（比如中文句子）所有token的、富含上下文信息的向量序列。
        
        - K = V = Encoder's final output
            
- **比喻**:
    
    - Q是你的**眼睛**，它带着“我现在要翻译‘苹果’这个词”的意图。
        
    - K是原文（Encoder输出）这本“字典”的**索引**。你的眼睛Q会扫过所有索引K，找到与“苹果”最相关的原文词（比如原文的“苹果”或“水果”）。
        
    - V是这本“字典”的**内容**。一旦你的眼睛Q通过索引K锁定了最相关的内容，它就会从V中把那部分内容“抄”过来，作为生成下一个词的参考。
diffusion：
- **Query (Q)**: 来自**图像**。U-Net会把当前的**图像特征向量**，经过一个线性层，生成Q向量。
    
    - Q代表了图像当前区域的“需求”：“我这块像素区域，正在尝试画一些红色的、崎岖的东西，我需要一些语义信息来指导我，我到底该画成什么样？”
        
- **Key (K) 和 Value (V)**: 来自**文本**。U-Net会把**文本提示的向量序列**，经过另外两个线性层，生成K和V向量。
    
    - K是文本提示的“可供查询的关键词索引”。
        
    - V是文本提示的“可供提取的语义内容”。
        
- **交互过程**:
    
    1. 图像的每一个区域（Query），都会去“阅读”一遍完整的文本提示（Key/Value）。
        
    2. Q @ K.T计算出了图像的某个特定区域，和文本提示中的**哪个词**（比如"horse", "mars", "astronaut"）关系最密切。
        
    3. 然后，这个区域就会重点从那个关系最密切的词的Value向量中**提取语义信息**。
        
    4. 这些提取出来的、带有文本语义的向量，会再被整合回U-Net的图像特征中，从而**指导**U-Net在下一步的去噪过程中，把这块区域画得更像“火星(mars)的地面”或者“马(horse)的身体”。


# 多头注意力复杂度
应该与单头注意力无任何区别，
n，d维度的矩阵乘法，时间复杂度n方， n，n维度与n，d维度相乘， 实际复杂度nd
所以n方＋nd？
- **结论要记牢**: 多头注意力的计算复杂度和单头是**一样**的。它没有增加计算量，只是把计算**重新分配**到了多个并行的、低维度的子空间中。
    
- **瓶颈要清楚**: 无论是单头还是多头，注意力的计算和空间瓶颈都在于那个与**序列长度n的平方**相关的项 (O(n²*d)和O(n²))。这就是为什么标准Transformer难以处理超长序列的原因。
    
- **面试回答思路**:
    
    1. 首先，明确给出结论：“多头注意力的计算复杂度与单头是相同的。”
        
    2. 然后，分析瓶颈：“两者的计算瓶颈都在于Q和K的点积，复杂度是O(n² * d)，其中n是序列长度，d是嵌入维度。”
        
    3. 最后，解释为什么一样：“因为多头注意力是将总的维度d，切分成了h个更小的维度d_k，然后在这些低维空间上并行计算。总的计算量 h * (n² * d_k) 等于 h * (n² * d/h)，正好等于n² * d，所以总计算量没有变化。”
# QA
> **为啥v矩阵不用我们定义的含义，”句子的信息“，而是又来一个线性层。”**

**你这个问题，极其敏锐！** 它完美地佐证了“涌现”的思想。

- **为什么不用原始的词嵌入作为V？** 如果我们直接用原始的x（词嵌入）作为Value，那么模型能提取的信息就被**限制**住了。
    
- **为什么需要一个独立的W_v线性层？**
    
    - x 包含了关于一个词的所有信息，但这些信息对于**不同的上下文**，其**“贡献”方式**应该是不同的。
        
    - W_v这个线性层，给了模型一个**自由度**。它允许模型去**学习**：“**当一个词准备‘贡献’信息给别人时，它应该呈现出一种什么样的‘姿态’才是最合适的？**”
        
    - 这个V向量，就是原始信息x经过一次“提炼”和“转换”后，得到的**最适合被加权求和**的表示。
        
    - 模型在训练中发现，把原始信息投影到一个**新的、独立的“价值子空间 (Value subspace)”**中，比直接使用原始信息能更好地降低损失。于是，W_v就学习到了这种最佳的投影方式。**这个最佳投影方式，不是被设计出来的，而是被优化出来的。**
        

---

## 涌现能力
我觉得”涌现能力“真的，有点难解释。 也就是说，attention的设计者，也没有想到过用三种矩阵就能效果这么好对吗？ 不然为啥v矩阵不用我们定义的含义，”句子的信息“，而是又来一个线性层。  
包括多头，其实代码操作的话，就仅仅是将维度分割。我们可没让那些维度关注哪些， 只是在独自训练，肚子反向传播的过程中，他们有了不同的能力。 就算概率学讲，他们三个头甚至可能在某轮训练中关注的一样，只要梯度下降相似，是这样吗