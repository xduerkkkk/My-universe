# 多头作用
从计算效率来看，多了并行处理计算，提高效率。 但是时间复杂度和单头是一模一样的啊？？？  同时还减小过拟合风险 
从模型效果来看，原来的单头注意力集中，可能只聚焦在一个特征，多头独立训练，独立梯度下降，就能捕捉不同的信息，能更全面的理解输入序列，助于模型学习复杂的语义 


# transformer为什么要设计这么多层
在attention机制的基础上，每一层都能进一步捕捉特征。不过这是直觉上的， 具体而言所谓提取“更高层次特征”，“捕捉复杂摸索和长距离依赖关系”。 不过还是有点难直观理解。
**知识补充 (用机器翻译举例)**:

- **浅层 (Bottom Layers, e.g., Layer 1-3)**:
    
    - **角色**: **词法和句法分析器**。
        
    - **学习内容**:
        
        - **词性**: 这一层可能学会了区分名词、动词、形容词。
            
        - **局部短语结构**: 注意力头可能在学习将“New”和“York”这两个token紧密联系在一起，形成一个不可分割的短语。
            
        - **基本的语法关系**: 比如主谓关系。
            
- **中层 (Middle Layers, e.g., Layer 4-8)**:
    
    - **角色**: **语义整合器**。
        
    - **学习内容**:
        
        - **消歧义 (Disambiguation)**: 在句子“The bank is closed”中，中层网络会利用上下文（比如前面提到了“river”），来确定这里的bank是“河岸”而不是“银行”。
            
        - **指代消解 (Coreference Resolution)**: 在“The cat chased the mouse until **it** got tired”中，中层网络会学习到it指代的是cat而不是mouse。
            
        - **长距离依赖**: 它会将句首和句尾的概念联系起来，理解整个句子的**核心语义**。
            
- **深层 (Top Layers, e.g., Layer 9-12)**:
    
    - **角色**: **意图与上下文建模器**。
        
    - **学习内容**:
        
        - **全局上下文与意图**: 在Encoder的顶层，输出的向量已经高度浓缩了整个源语言句子的意图。
            
        - **特定于任务的表示**: 在Decoder的顶层，输出的向量会结合源语言的意图和已经生成的目标语言，做出最适合生成下一个词的决策。这里的表示已经是高度抽象和任务导向的了。
# transformer为什么要把全连接层映射到高维度然后映射回来
直观理解，去更高的维度就是为了捕获更多的信息，学习更复杂的特征的， 而且升到高维后紧接着进行激活函数的非线性变化？ 就更复杂了
然后再低维回来，把刚才高维学的知识消化消化，整合压缩。 输入输出维度一致，才能继续后续操作

# 这么多层怎么不过拟合？
所以在设计的时候 ， 每一层都有dropout，在损失函数都使用了正则化
训练过程使用early stopping监控 
不过所谓的“大规模数据集预训练他，特定任务微调，可以利用大数据的统计特性减少过拟合”我有点不理解

- **一个在海量文本上预训练好的LLM，已经“学到”了什么？**
    
    1. **语言的通用模式**: 它学会了语法、句法、词法。它知道主谓宾，知道单复数，知道时态。
        
    2. **世界知识 (World Knowledge)**: 它“读”过了维基百科，知道了“巴黎是法国的首都”，“水在100摄氏度会沸腾”。这些知识以某种形式存储在它亿万的参数中。
        
    3. **常识推理 (Common-sense Reasoning)**: 它学会了如果“A比B大，B比C大”，那么“A比C大”。
        
- **这些“学到”的东西，为什么能帮助它在小样本任务上避免过拟合？**
    
    - **强大的先验知识 (Strong Prior)**: 当你让这个“博学的教授”（预训练模型）来学习一个只有几百个样本的“法律文书分类”任务时，它**不是从零开始**的。
        
    - **它不会去死记硬背**: 它不会去记“‘合同纠纷’这个词组出现，就分类为A”。
        
    - **它会去理解和泛化**: 它会利用自己脑中已有的庞大语言和知识体系，去**理解**这份法律文书的**语义**。它看到“合同纠纷”，会立刻联想到“违约”、“责任”、“法律”等一系列相关的概念。
        
    - **微调 (Fine-tuning)** 的本质，是让模型学会如何**应用**它已有的知识，来解决你这个新的、特定的任务。它需要学习的，只是一个从“通用知识”到“特定任务”的**映射**，而不需要重新学习语言本身。
        
    - 因为模型依赖的是它强大的、从海量数据中学来的**泛化能力**，而不是去拟合你这几百个样本的**表面统计特征**，所以它自然而然地就**抵抗了过拟合**。
        

**比喻**:
- **不预训练，直接在小数据集上训练**: 就像让一个**婴儿**只看100张法律文书，然后让他去当法官。他除了死记硬背，别无他法。
    
- **预训练+微调**: 就像让一个**读完了整个图书馆的法学博士**，再来看这100张文书，然后让他去当法官。他会立刻理解这些文书的本质，并做出准确的判断。他学到的是“法理”，而不是“题库
