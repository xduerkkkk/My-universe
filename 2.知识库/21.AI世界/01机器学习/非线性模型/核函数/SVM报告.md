# 实验报告二：基于支持向量机 (SVM) 的图像分类研究

## 一、 实验目的
1.  理解 **支持向量机 (SVM)** 的核心思想（最大间隔超平面、支持向量）。
2.  掌握 SVM 中不同 **核函数 (Kernel Functions)** 的作用，特别是 **线性核 (Linear)** 与 **径向基核 (RBF)** 的区别与适用场景。
3.  掌握复杂图像数据集的处理方法，包括 gzip 压缩文件的解析、`.tar.gz` 归档文件的解压以及 **HDF5 格式 (v7.3 .mat)** 数据的读取。
4.  在 **MNIST** (实验室环境) 和 **SVHN** (真实世界环境) 两个数据集上验证并对比 SVM 的分类性能。

## 二、 实验环境与数据集
*   **编程语言**：Python 3.x
*   **主要依赖库**：`scikit-learn`, `numpy`, `scipy`, `matplotlib`, `h5py`, `tarfile`, `gzip`, `PIL`
*   **实验数据集**：
    1.  **MNIST 手写数字数据集**：包含 60,000 张 28x28 的灰度手写数字图片。数据格式为 `.gz` 压缩的 IDX 文件。代表了特征相对清晰、背景简单的理想分类任务。
    2.  **SVHN (Street View House Numbers) 数据集**：包含从 Google 街景图像中提取的真实门牌号图片 (Format 2: Cropped Digits)。数据格式为打包在 `.tar.gz` 中的 v7.3 `.mat` 文件。代表了背景复杂、光照多变的真实世界分类任务。

## 三、 算法原理

### 3.1 SVM 基本思想
支持向量机 (SVM) 是一种二分类模型（通过一对多策略可扩展至多分类）。其基本模型是定义在特征空间上的间隔最大的线性分类器。
*   **决策边界 (Hyperplane)**：SVM 寻找一个超平面来分割不同类别的样本。
*   **最大间隔 (Max Margin)**：SVM 的目标是找到一个不仅能正确分类，而且能使两类样本到超平面的最近距离（即间隔）最大化的超平面。
*   **支持向量 (Support Vectors)**：那些距离超平面最近的样本点。只有这些点决定了超平面的位置，其他样本点对模型没有影响。

### 3.2 核函数 (Kernel Trick)
当样本在原始空间中线性不可分时，SVM 引入核函数将样本映射到高维空间，使其在高维空间中线性可分。本实验对比了两种核函数：
1.  **线性核 (Linear Kernel)**：
    *   公式：$K(x, y) = x^T y + c$
    *   特点：计算速度快，适用于特征维度高、数据线性可分的情况。
2.  **径向基核 (RBF Kernel) / 高斯核**：
    *   公式：$K(x, y) = \exp(-\gamma ||x-y||^2)$
    *   特点：可以将数据映射到无限维空间，具有强大的非线性处理能力。是处理复杂、非线性数据的首选核函数。

---