- **P类问题 (Polynomial time)**：这类问题像是“**验证一条路**”。如果我给你一张地图，上面画好了走出迷宫的路线，你只需要沿着路线走一遍，就可以很快地（在有限、可接受的时间内）验证这条路到底对不对。**P问题就是那些“容易解决”的问题。**
    
- **NP类问题 (Nondeterministic Polynomial time)**：这类问题像是“**找到一条路**”。在没有地图的情况下，让你自己去找出走出迷宫的路。这可能会非常非常困难，你可能需要尝试无数条岔路，花费极长的时间。但是，一旦你**侥幸**找到了一条路，让别人来**验证**它是否正确却非常容易（就像P问题一样）。**NP问题就是那些“可能很难解决，但容易验证答案”的问题。**

**核心问题 P = NP?**  
计算机科学界最大的未解之谜就是：**P和NP这两类问题是等价的吗？**

- 如果 **P = NP**，意味着所有“容易验证答案”的问题，也一定“容易解决”。也就是说，找到走出迷宫的路，和你拿着地图验证路线，本质上是一样简单的。这会颠覆世界，因为许多加密算法、物流优化等难题都会被瞬间破解。
    
- 绝大多数科学家相信 **P ≠ NP**，即**“找到答案”确实比“验证答案”要困难得多**


既然我们无法从理论上根除过拟合，而且模型复杂度的选择也是一个“权衡”，我们总不能凭感觉来吧？

在实践中，我们必须有一套**可靠的方法**，来**评估**一个训练好的模型到底有没有过拟合，以及它的“泛化能力”到底有多强

Note that testing set should be mutually exclusive with the trainingset.
disjoint sets
The partition of training/testing sets should keep the consistency of data.
In classification tasks, the ratio of samples of each class should be kept.
From a sampling perspective, partition keeping the ratio can be obtained by a stratified sampling strategy.
Even the ratio has been kept, there are multiple ways to make the partition.
Different partition of training/testing sets will give different evaluation results.
When using the hold-out method, multiple random partition and experiments should be conducted, and use the average performance.
computational


| 方法                     | 优点                         | 缺点                      |
| ---------------------- | -------------------------- | ----------------------- |
| **留出法 (Hold-out)**     | 简单，计算开销最小。                 | 评估结果偶然性大；训练集变小，评估结果有偏差。 |
| **k折交叉验证 (k-Fold CV)** | 充分利用数据，评估结果稳健可靠，是目前最主流的方法。 | 计算开销是留出法的k倍。            |
| **留一法 (LOO)**          | 评估结果最稳定，最接近真实模型的性能。        | 计算开销极大，不适用于大数据集。        |

## 自助采样

1. 自助法创造出来的训练集 D' 和原始数据集 D 有什么异同？（比如大小、样本重复情况）
    
2. PPT第15页提到，大约有36.8%的原始数据不会出现在采样生成的训练集 D' 中。这部分数据被称作“**包外估计 (out-of-bag estimate)**”，它们可以用来做什么呢

1.D中数据有的不会出现在D'，有的又会重复出现，这是抽样性质决定的。但是总大小是一样的吧。  
2， 等下，我要感叹一下，怎么这么巧合！为什么恰好，这个“没出现”的概率公式，m取极限就是一个重要极限？好巧啊！  
然后，这些... 这些难道做测试集？虽然我没想到逻辑... 所在

它通过抽样，既维持了训练集的大小 (m)，又凭空“创造”出了一个约占数据总量1/3的测试集。这意味着，我们用到了**和原始数据规模一样大**的训练集来训练模型（尽管有重复数据），这比留出法和交叉验证在单次训练中使用的训练数据都要多。这在**数据集本身很小、不适合再进行划分**的情况下，尤其有用。

