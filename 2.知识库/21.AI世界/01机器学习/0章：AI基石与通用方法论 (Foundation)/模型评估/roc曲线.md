ROC曲线的两个关键坐标轴：

- **纵轴：真正例率 (True Positive Rate, TPR)**
    
- **横轴：假正例率 (False Positive Rate, FPR)**


TPR，分母是所有真实的positive例子，分子是TP
诶，这不就是recall吗？ 真实的positive中，成功的找回了多少？
越大越好，

FPR，分母是所有真实的negative例子，分子是，FP
所有真实的negative中，错判成positive的有多少？
这个衡量的，就是把坏人放过的比例，越大越糟糕

看起来 这俩分子都是判断成positive的情况


P-R曲线分类阈值是置信度，核心还是想尽可能找全positive的同时少点误报
ROC曲线的分类阈值？
其核心变成少误报吗？ 那估计也是置信度，但是倾向于降低？


- **P-R曲线 (精确率 vs 召回率)**：
    
    - 它的两个轴 (Precision = TP/(TP+FP), Recall = TP/(TP+FN)) 都只关注**正例 (Positive)**。它回答的是：“我找出来的这堆‘坏人’纯度高不高？我把所有‘坏人’都找全了吗？”
        
    - **适用场景**：它更关心模型在**正例**上的表现，特别是在**正例样本数量远少于负例样本**（即数据不均衡）的情况下，P-R曲线能更直观地反映模型的性能。
        
- **ROC曲线 (TPR vs FPR)**：
    
    - 它的两个轴 (TPR = TP/(TP+FN), FPR = FP/(FP+TN))，一个关注**正例**的表现（找全了多少坏人），另一个关注**负例**的表现（错怪了多少好人）。
        
    - 它衡量的是一种**“收益”与“代价”之间的权衡**：我为了多找出一些坏人（提高TPR），需要付出多错怪一些好人（提高FPR）的代价。
        
    - **适用场景**：它能很好地衡量模型在**不同阈值**下，识别正负样本的**综合能力**，尤其是在评估模型的**排序质量**（即模型是否能很好地把正例排在负例前面）时非常有用。当数据类别分布比较均衡时，ROC曲线的表现更稳定。

# 绘图过程
1. 从 (0,0) 点开始。
    
2. 将所有样本按预测概率从高到低排序。
    
3. 依次遍历每个样本：
    
    - 如果这个样本是**真正的正例 (Positive)**，就在**Y轴**方向（向上）移动 1 / (总正例数) 的距离。
        
    - 如果这个样本是**真正的负例 (Negative)**，就在**X轴**方向（向右）移动 1 / (总负例数) 的距离。
        
4. 把这些移动的轨迹连接起来，就是ROC曲线。
