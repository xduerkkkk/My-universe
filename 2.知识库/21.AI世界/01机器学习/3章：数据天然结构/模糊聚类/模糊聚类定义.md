- 在**K-Means (硬聚类)**中，当我们计算某个聚类中心（比如C_1）的新位置时，我们**只**使用那些被分配给C_1的样本。其他样本对C_1的位置**毫无影响**。
    
- 在**FCM (软聚类)**中，情况变了。算法认为**每个样本都对每个聚类中心的位置有影响**，只是影响的**权重**不同。一个样本离某个中心越近，它的隶属度就越高，它在计算这个中心的新位置时的“发言权”就越大。反之，离得远的样本，隶属度很低，发言权几乎可以忽略不计，但理论上依然存在。

- 当 b **趋近于1**时：
    
    - 隶属度的计算会变得非常“极端”。对于一个样本，离它最近的那个中心的隶属度会趋近于1，而离其他中心的隶属度会趋近于0。
        
    - 此时，FCM的结果就**无限接近于K-Means (硬聚类)**。
        
- 当 b **越大**时：
    
    - 隶属度的计算会变得越来越“平均”。一个样本对各个簇的隶属度差异会越来越小。
        
    - 当 b 趋于无穷大时，所有样本对所有簇的隶属度都会变成 1/C (C是簇的数量)，相当于完全模糊，聚类失去了意义。



$$m_j = \frac{∑[μ_j(x_i)]^b * x_i) }{ (∑[μ_j(x_i)]^b)}$$

$$μ_j(x_i) = (1 / ||x_i - m_j||^2)^(1/(b-1)) / ∑[(1 / ||x_i - m_l||^2)^(1/(b-1))]$$

### **引导思考 ❓：FCM vs. GMM 公式对比 (修正版)**

你说“簇更新的时候，我怎么感觉加权是一样的呢？”。你的感觉基本是对的！它们的核心思想都是“加权平均”。但魔鬼在细节中，我们来仔细看看这个“权”。

#### **差异1：计算“归属度”的核心度量不同**

*   **FCM (更新隶属度 `μ`)**:
    $$
    \mu_{j}(x_i) \propto \left( \frac{1}{\|x_i-m_j\|^2} \right)^{\frac{1}{b-1}}
    $$
    它的核心度量是 **欧式距离的倒数** (`1/距离^2`)。这是一个非常简单、直观的度量。它只关心“远近”。

*   **GMM (更新后验概率 `γ`)**:
    $$
    \gamma(i,k) \propto \pi_k \cdot \mathcal{N}(x_i | \mu_k, \Sigma_k)
    $$
    它的核心度量是 **高斯概率密度** $\mathcal{N}$，这是一个更复杂的东西。它不仅包含了距离（体现在 $\mu_k$ 上），还包含了两个额外信息：
    1.  **簇的形状和方向 (`Σ_k`)**: 一个点即使离两个簇中心的距离相同，但如果它更符合其中一个簇的**形状**（比如一个瘦长的椭圆），那么它的概率也会更高。
    2.  **簇的先验权重 (`π_k`)**: 即使一个点在两个簇的概率密度相同，但如果一个簇本身更大（`π_k`值高），那么这个点属于这个大簇的最终概率也会更高。

**小结1：** FCM的归属度只看**距离**；GMM的归属度综合考虑了**距离、簇的形状和簇的大小**。

---

#### **差异2：更新“簇中心”时，权重本身不同**

*   **FCM (更新中心 `m_j`)**:
    $$
    m_j = \frac{\sum_{i=1}^{N} (\mu_{j}(x_i)^b) \cdot x_i}{\sum_{i=1}^{N} \mu_{j}(x_i)^b}
    $$
    这里用来加权的“权重”是**隶属度的 `b` 次方** (`μ^b`)。

*   **GMM (更新均值 `μ_k`)**:
    $$
    \mu_k = \frac{\sum_{i=1}^{N} \gamma(i,k) \cdot x_i}{\sum_{i=1}^{N} \gamma(i,k)}
    $$
    这里用来加权的“权重”是**后验概率本身** (`γ`)。

**小结2：** 虽然都是加权平均，但FCM在M步使用的权重 (`μ^b`) 和它在E步计算出的归属度 (`μ`) 之间，还多了一个 `b` 次方的变换。而GMM在M步是直接使用E步计算出的归属度 (`γ`) 作为权重。

---
### **总结 (❗)**

现在你能更清晰地看到差异了吗？
1.  **归属度计算的依据不同**: FCM更简单，只依赖距离；GMM更复杂，是基于一个完整的概率模型。
2.  **M步加权方式有细微差别**: FCM的权重是隶属度的`b`次方，GMM的权重是后验概率本身。

这些差异导致了我们之前的结论：FCM倾向于发现**球状**的簇（因为它只看距离），而GMM可以发现更灵活的**椭球状**的簇。

---
我们已经深入探讨了GMM和FCM。现在，让我们进入最后一个主题。

**学习单元 (Learning Unit) 10:**
请阅读 **第88页至第94页**。这部分介绍了与之前“划分式聚类”完全不同的另一种思路——**层次聚类 (Hierarchical Clustering)**。

**引导思考 ❓:**
在 **第92页**，PPT提出了一个关键问题：“2个簇，4个簇，还是16个簇？”。你认为，相比于K-Means或FCM这种需要我们**预先指定簇数量K**的算法，层次聚类最大的优势是什么？它试图解决一个什么样的痛点？

