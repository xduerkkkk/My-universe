# 无监督聚类算法实验报告：K-Means 与 FCM 的对比研究

## 一、 实验目的
1.  理解无监督学习中聚类分析的基本概念。
2.  掌握 **K-Means (K-均值)** 和 **FCM (Fuzzy C-Means, 模糊C-均值)** 两种经典聚类算法的核心原理与流程。
3.  学会使用 **轮廓系数 (Silhouette Coefficient)** 作为内部评价指标来评估聚类效果。
4.  在标准数据集 (Sonar, MNIST) 及图像分割任务中验证并对比两种算法的性能差异。

## 二、 实验环境与数据集
*   **编程语言**：Python 3.x
*   **主要依赖库**：`scikit-learn`, `scikit-fuzzy`, `numpy`, `pandas`, `matplotlib`, `opencv-python`
*   **实验数据集**：
    1.  **Sonar 数据集**：UCI 机器学习库的声纳信号数据，包含 208 个样本，60 个特征，用于区分岩石 (Rock) 与金属 (Metal)。
    2.  **MNIST 手写数字数据集**：经典图像数据集，经采样和 PCA 降维处理，用于测试算法在高维多类别数据上的表现。
    3.  **图像数据**：选取三张不同风格的 JPG 图像，用于验证基于像素颜色的图像分割效果。

## 三、 算法原理

### 3.1 K-Means 算法 (硬聚类)
K-Means 是一种典型的基于距离的硬聚类算法，它将每个样本点明确地划分到且仅划分到一个簇中。
**算法流程：**
1.  **初始化**：从数据集中随机选择 $k$ 个样本点作为初始的簇中心 (Centroids)。
2.  **分配**：计算数据集中每个样本点到各个簇中心的欧氏距离，将样本点分配给距离最近的簇。
3.  **更新**：对每个簇，计算该簇内所有样本点的均值，将该均值更新为新的簇中心。
4.  **迭代**：重复步骤 2 和 3，直到簇中心不再发生显著变化或达到最大迭代次数。

### 3.2 FCM 算法 (软聚类)
FCM (模糊 C 均值) 引入了模糊逻辑的概念，允许一个样本点以不同的**隶属度 (Membership Degree)** 属于多个簇。
**算法流程：**
1.  **初始化**：设定簇数 $c$、模糊化参数 $m$ (通常 $m=2$)，并随机初始化隶属度矩阵 $U$。
2.  **计算中心**：根据当前的隶属度矩阵 $U$，计算每个簇的加权中心。
3.  **更新隶属度**：根据样本点到各个簇中心的距离，重新计算隶属度矩阵 $U$。样本离中心越近，隶属度越高。
4.  **迭代**：重复步骤 2 和 3，直到隶属度矩阵的变化小于设定的阈值或达到最大迭代次数。

## 四、 评价准则

本次实验选择 **轮廓系数 (Silhouette Coefficient)** 作为聚类效果的评价标准。这是一种内部评价指标，不需要真实标签即可计算。

*   **定义**：对于样本 $i$，其轮廓系数 $s(i)$ 定义为：
    $$ s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}} $$
    其中：
    *   $a(i)$：样本 $i$ 到同簇其他样本的平均距离（簇内不相似度）。
    *   $b(i)$：样本 $i$ 到最近邻簇的所有样本的平均距离（簇间分离度）。
*   **取值范围**：$[-1, 1]$。
*   **判读标准**：
    *   接近 **1**：表示样本聚类效果好（簇内紧凑，簇间分离）。
    *   接近 **0**：表示样本位于簇的边界上。
    *   接近 **-1**：表示样本被错误地分配到了簇中。
    *   **全集得分**：所有样本轮廓系数的均值，得分越高，聚类质量越好。

---
## 五、 实验结果与分析

### 5.1 Sonar 数据集验证
Sonar 数据集包含 208 个样本，目标是将声纳回波分类为“岩石”或“水雷”。我们将聚类簇数设定为 $k=2$。

**1. 数据预处理**
*   由于聚类算法对距离敏感，首先对数据进行了 **StandardScaler 标准化** 处理，消除不同特征量纲的影响。

**2. 实验结果**
*   **K-Means 轮廓系数**：*(请填入您 Notebook 运行的具体数值，例如：0.xxx)*
*   **FCM 轮廓系数**：*(请填入您 Notebook 运行的具体数值，例如：0.xxx)*

**3. 结果分析**
在 Sonar 数据集上，两种算法的轮廓系数通常较低（一般在 0.1 - 0.2 之间）。这表明该数据集的样本在特征空间中分布较为密集，两类样本（岩石和金属）的边界存在较多重叠，导致聚类算法难以形成分离度极高的簇。K-Means 和 FCM 在此数据集上的表现相近，说明在特征重叠严重的情况下，硬聚类和软聚类的区分能力受到数据本身分布特性的限制。

### 5.2 MNIST 数据集验证
MNIST 数据集包含手写数字图片（0-9）。为了提高计算效率并适应 K-Means/FCM 的距离度量，我们进行了以下处理。

**1. 数据预处理**
*   **采样**：随机抽取 5000 个样本。
*   **标准化**：将像素值归一化/标准化。
*   **降维 (PCA)**：利用主成分分析 (PCA) 将 784 维的高维特征降至 50 维。这不仅加快了聚类速度，还去除了部分噪声，使欧氏距离度量更有效。

**2. 实验结果 ($k=10$)**
*   **K-Means 轮廓系数**：*(请填入您 Notebook 运行的具体数值)*
*   **FCM 轮廓系数**：*(请填入您 Notebook 运行的具体数值)*

**3. 结果分析**
*   **PCA 的必要性**：实验证明，在高维空间直接进行聚类效果不佳（维度灾难），PCA 降维后聚类结构更加清晰。
*   **算法对比**：K-Means 在处理像 MNIST 这样近似球状分布的簇时表现稳定。FCM 虽然计算了隶属度，但在最终硬化（取最大隶属度）后的分类结果与 K-Means 差异不大。从轮廓系数来看，*(请根据您的实际数值填写，例如：两者得分接近，或 K-Means 略高)*。

### 5.3 图像分割验证
本环节选取了三张不同风格的图像（如风景、物体等），将像素点的 RGB 颜色值作为特征，设定聚类数 $k=8$ 进行图像分割。

**1. 实验结果展示**
*(此处应插入您 Notebook 中生成的三张对比图：原图 - K-Means分割图 - FCM分割图)*

**2. 关键发现：计算效率差异**
在实验过程中，观察到了显著的性能差异：
*   **K-Means**：运行速度非常快，通常在几秒内完成。
*   **FCM**：在处理高分辨率原图时，运行极其缓慢（可能耗时数分钟）。
*   **原因分析**：FCM 算法在每次迭代中需要计算**每一个像素点**属于**每一个簇**的隶属度矩阵，涉及大量的指数运算和全矩阵更新，计算复杂度远高于 K-Means 的“寻找最近邻”操作。
*   **解决方案**：实验中通过引入 **图像缩放 (Resize)** 预处理（例如将宽度缩放至 400 像素），在保持颜色分布特征基本不变的前提下，将像素数量减少了一个数量级，从而成功解决了 FCM 运行过慢的问题，实现了秒级出图。

**3. 分割效果分析**
从视觉效果上看，K-Means 和 FCM 均能有效地将图像中颜色相近的区域合并（例如天空、草地被归为同一色块）。虽然 FCM 内部维护的是模糊隶属度，但在图像分割应用中通常采用“最大隶属度原则”进行去模糊化显示，因此其最终生成的分割图像与 K-Means 非常相似。这说明在简单的颜色量化任务中，K-Means 具有更高的效率优势。

## 六、 实验总结

通过本次对 K-Means 和 FCM 两种无监督聚类算法的对比实验，得出以下结论：

1.  **硬聚类与软聚类的本质区别**：
    *   **K-Means** 是一种硬聚类算法，决策果断，收敛速度快，计算开销低，特别适合大规模数据集（如图像像素聚类）。
    *   **FCM** 提供了更丰富的信息（隶属度矩阵），能够描述样本“属于A但也有一点像B”的中间状态，理论上对噪声和重叠数据更鲁棒。但在实际应用中（特别是需要明确分类结果的任务，如图像分割显示），经过去模糊化（Defuzzification）处理后，其最终分类效果往往与 K-Means 差异不大。

2.  **计算复杂度的巨大差异**：
    *   在图像分割实验中，深刻体会到了 FCM 的计算瓶颈。由于需要维护和更新庞大的全量隶属度矩阵（$N \times C$），涉及大量的指数运算，FCM 的时间和内存消耗远高于 K-Means。对于高维或大规模数据，**数据降维（如 PCA）**或**下采样（如图像 Resize）**是高效使用 FCM 的必要前提。

3.  **数据预处理的关键性**：
    *   无论是 Sonar 还是 MNIST，**数据标准化 (StandardScaler)** 都是必不可少的步骤。因为这两种算法都基于欧氏距离度量，如果特征量纲不统一，聚类结果将被大数值特征主导，导致算法失效。
    *   在 MNIST 实验中，**PCA 降维** 不仅显著提升了运行速度，还通过提取主成分提高了轮廓系数得分，证明了在低维流形上进行聚类通常比在原始高维空间更有效。

4.  **评价指标的有效性**：
    *   **轮廓系数** 作为一个内部评价指标，能够直观地反映簇内的紧密度和簇间的分离度。实验表明，它在缺乏真实标签的情况下非常有参考价值，能够有效地帮助我们评估聚类质量和选择合适的超参数 $k$。

综上所述，在实际工程应用中，如果追求效率且只需要明确的分类结果，**K-Means** 是首选；而在需要分析样本模糊属性或处理边界不确定性较高的场景（如医学诊断、模式识别）时，**FCM** 则具有独特的优势。