### **核心概念 (Core Concepts)**

- **Machine Learning (ML)**: 机器学习
    
- **Supervised Learning**: 监督学习
    
- **Unsupervised Learning**: 非监督学习
    
- **Reinforcement Learning**: 强化学习
    
- **Regression**: 回归 (预测连续值)
    
- **Classification**: 分类 (预测离散类别)
    
- **Model**: 模型
    
- **Algorithm**: 算法
    
- **Parameters**: 参数 (模型从数据中学习到的东西，如 θ 或 w)
    
- **Hyperparameters**: 超参数 (需要我们手动设定的参数，如学习率 alpha、正则化强度 lambda)
    
- **Training Set**: 训练集 (用来训练模型的数据)
    
- **Test Set**: 测试集 (用来评估模型泛化能力的数据)
    
- **Features**: 特征 (输入的变量，如 x₁, x₂)
    
- **Label / Target**: 标签 / 目标 (需要预测的真实值 y)
    

---

### **线性回归 (Linear Regression)**

- **Linear Model**: 线性模型 (一个总称)
    
- **Hypothesis Function**: 假设函数 (模型的数学表达，h(x))
    
- **Weights / Coefficients**: 权重 / 系数 (θ₁, θ₂, ...)
    
- **Bias / Intercept**: 偏置 / 截距 (θ₀)
    
- **Loss Function / Cost Function**: 损失函数 / 代价函数 (J(θ))
    
- **Mean SquaredError (MSE) / L2 Loss**: 均方误差 / L2损失 (线性回归的代价函数)
    
- **Gradient Descent**: 梯度下降 (优化算法)
    
- **Learning Rate**: 学习率 (alpha)
    
- **Vectorization**: 向量化 (用矩阵运算代替循环)
    
- **Normal Equation**: 正规方程 (线性回归的闭式解)
    

---

### **逻辑回归与分类 (Logistic Regression & Classification)**

- **Logistic Regression**: 逻辑回归
    
- **Binary Classification**: 二分类
    
- **Multiclass Classification**: 多分类
    
- **Discriminant Function**: 鉴别函数
    
- **Decision Boundary**: 决策边界 (分割不同类别的线或面)
    
- **Decision Surface**: 决策面 (决策边界的另一种说法)
    
- **Sigmoid Function / Logistic Function**: Sigmoid函数 / Logistic函数
    
- **Probability**: 概率
    
- **Log Loss / Cross-Entropy Loss**: 对数损失 / 交叉熵损失 (逻辑回归的代价函数)
    
- **Maximum Likelihood Estimation (MLE)**: 最大似然估计 (推导交叉熵的理论基础)
    

---

### **模型评估与改进 (Model Evaluation & Improvement)**

- **Bias**: 偏差 (导致欠拟合)
    
- **Variance**: 方差 (导致过拟合)
    
- **Bias-Variance Tradeoff**: 偏差-方差权衡
    
- **Underfitting**: 欠拟合
    
- **Overfitting**: 过拟合
    
- **Generalization**: 泛化 (模型在未知数据上的表现能力)
    
- **Regularization**: 正则化 (防止过拟合的技术)
    
- **L1/L2 Regularization**: L1/L2 正则化
    
- **Lambda (λ)**: 正则化强度/系数
    
- **Feature Scaling**: 特征缩放
    
- **Normalization / Standardization**: 归一化 / 标准化
    
- **Feature Mapping**: 特征映射 (创造多项式特征)
    

---

### **高级优化算法 (Advanced Optimization)**

- **Batch Gradient Descent (BGD)**: 批梯度下降
    
- **Stochastic Gradient Descent (SGD)**: 随机梯度下降
    
- **Mini-Batch Gradient Descent**: 小批量梯度下降
    
- **Convergence**: 收敛 (算法找到最优解)
    
- **Divergence**: 发散 (算法结果越来越差)
    
- **Momentum**: 动量 (一种加速梯度下降的方法)
    
- **Adam (Adaptive Moment Estimation)**: Adam优化器