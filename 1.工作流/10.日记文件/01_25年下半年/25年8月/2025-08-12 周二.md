

---
# 今天想说的话

好，我使用的是wsl下的linux，环境管理用的conda create web。 我们进行下一步吧，然后知识库我不太想加载我的，我的md文件没有多少，而且还在完善，有没有其他思路
## 困惑一
Bellman_ford为啥是直接“松弛” n-1次  然后就一定找到最短路径？
```
初始化edges ： 点1，点2，权值
初始化minDist   除了minDist【1】为0外其他都是无穷大

for循环 最多遍历n-1次：
	updated = False  用于提前打断循环，如果不更新了，那就得到结果了，不用再费时间循环了
	for循环 遍历每个边：
		对每个边进行松弛操作
		即 if minDist【点1】 ！= 无穷 且 mindist【点1】+weight < mindist【点2】
		意思是如果点2以点1为桥梁，能距离源点更近的话
		更新mindist【点2】 = mindist【点1】 + weight
```
为什么遍历n-1次呢，其实这个算法也不知道到底遍历多少次，我就能找到最短路径，他只知道最坏情况下，就遍历n-1次，所以把总次数设立为n-1.中途不update了再跳出就行。

所以我们遍历次数大于n，和遍历n-1次，得到的结果是一模一样的。
但是！ 若图中有负权回路，那就会变小。所以可以通过第n次遍历，比较第n-1次遍历，判断图中是否有负权回路

## 困惑二
我以为flashattention的softmax是qkv全部相乘后计算的，其实就是先算p（注意力分数）再乘v，这个p是softmax过的？ 
是，这里精确一下名称：S是qk相乘，n×n的矩阵，是注意力分数。然后应用softmax，得到的注意力权重矩阵P， 最后的输出，PV，称作O。flashattention是把S、P的计算，一步到位，采用tiling和online softmax

怎么进行online softmax的？
维护全局变量sum和max， 我们直接把结果先写入n乘d_n，也就是O那个输出矩阵， 后续再不断基于新sum和max对结果进行更新

softmax是针对n乘n矩阵的一列，进行运算的。不过，这一列也被我们分块了。那么flashattention，需要存储的，是当前列，目前最大softmax值，还有当前时间步为止的，sun和，。  这俩，都是o（1
）的空间复杂度吧？？  最后就是，n乘n_d这个输出矩阵。 所以总的空间复杂度就是O（n）
那访问次数呢？ 我们一共访问了哪些？ 访问的时间复杂度是多少
标准
- **读取**：Q,K,V (各一次) + S (一次) = 3Nd+N2
    
- **写入**：S (一次) + O (一次) = N2+Ndv​
    
- **总计**：2N2+3Nd+Nd
flashattention：
- **读取**：Q,K,V (各一次) = Nd+Nd+Ndv​
    
- **写入**：O (一次) = Ndv​
    
- **总计**：2Nd+2Ndv

嗯，然后就是，我的理解，nd_model 这个输出矩阵，每个格子都是pv的结果，没问题吧？ 但每个格子，softmax之后的p，是要一直随着全局m和l调整的，对吗？ 那这个更新如何做呢？



📒遇到的问题


## 今日目标
第一个为主线任务
1. [ ] 
2. [ ] 
3. [ ] 

## 主线任务拆解
最终目标：
里程碑：



## 今日完成
- [ ] 
- [ ] 
- [ ] 

## 今日总结

## 明日计划
- [ ] 
- [ ] 
- [ ] 




