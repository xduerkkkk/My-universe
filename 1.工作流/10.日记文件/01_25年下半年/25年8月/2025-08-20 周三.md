

---
# 今天想说的话

block单位 是标准的“卷积+归一化+激活”  输出维度dim_out
mlp  激活+全连接 输出的维度是dim_out
ResnetBlock
1. block1
2. mlp  通过rearrange注入时间给上一步输出的图像向量
3. block2 
4. 加残差
- 残差是最初的x映射到dim_out的样子


unet的下采样，是先经过block、attention后，保存当前图的高清特征，全局特征，然后再下采样缩小。
结束后，每次上采样前，先把之前保存的特征添加到当前向量，再上采样。
时间步，是每一步都存在的。
这样，势必最后一次下采样前保存的特征，会用在第一次上采样。这叫跳跃连接
## 困惑一 无条件diffusion的unet，为什么也要加入selfattention
**场景：模型正在生成一张人脸。**

1. **没有 Self-Attention (只有卷积)**:
    
    - 模型现在正在画**右眼**。卷积操作的感受野（它能“看到”的范围）是**局部**的。这意味着，在画右眼时，模型很难“看到”它刚刚在图片另一边画好的**左眼**是什么样的。
        
    - **结果会怎样？** 模型可能会画出一只蓝色的左眼和一只棕色的右眼，或者两只眼睛大小、风格不一致。因为它缺乏一个**全局的协调机制**。
        
2. **有了 Self-Attention**:
    
    - 模型同样在画**右眼**。但现在，构成右眼的那些像素特征，可以**attend to (关注)** 图片上的**所有**其他像素！
        
    - **会发生什么？** 右眼区域的像素 Query，会和左眼区域的像素 Key 计算出**非常高的相似度**。
        
    - 这意味着，在计算右眼的最终特征时，模型会大量地**加权求和**左眼的像素 Value。它等于直接从左眼那里“抄作业”，获取了关于**颜色、形状、风格**的关键信息。
        
    - **最终结果**：模型能够画出对称、一致的两只眼睛。
        

**这就是“捕捉长距离依赖关系”的一个具体体现**：让图片的两个相距很远的部分（左眼和右眼）能够直接沟通，保证全局的和谐与一致性。同理，它也能保证一件衣服上的花纹是连贯的，或者一辆车的两个轮子是匹配的。

## 困惑二三
c++是编译 python不是编译吗？ 我还记得什么解释性语言 这个名词又是啥意思？什么叫类型检查是在程序运行时进行的？ 为什么？ 到底怎么操作的

计组学过的，给忘了。 与编译型语言对应的就是解释型语言，编译型语言会将我们的代码变成汇编语言，再由汇编程序处理为机器语言，再执行机器语言。
解释型其实也编译，python是这样的 
源码 → **编译器** → 字节码（.pyc）→ **解释器/虚拟机** → 一条条执行。

所以 Python 也“编译”，只是它编译到字节码就停了，再由解释器在运行时把字节码一条条解释成机器动作。  
因此说“Python 不是编译”是口语化说法，准确说应是“Python 不是**提前完全编译到机器码**

解释型语言的好处是启动快，调试更灵活，但运行开销大
正因为是解释型语言，所以类型检查只能在程序运行时进行呀， 编译型语言编译的时候就能发现问题，在运行前。 
## 困惑四
stable diffusion3的dit， 他的模仿vit+selfattention+图文crossattention 
和 之前diffusion的 unet+selfattention 有什么区别
## 今日目标
第一个为主线任务
1. [ ] 
2. [ ] 
3. [ ] 

## 主线任务拆解
最终目标：
里程碑：



## 今日完成
- [ ] 
- [ ] 
- [ ] 

## 今日总结

## 明日计划
- [ ] 
- [ ] 
- [ ] 




